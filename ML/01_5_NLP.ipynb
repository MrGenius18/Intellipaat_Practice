{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author:- **Bhautik Gondaliya**\n",
    "\n",
    "mo. no.:- **[9586280240](https://)**\n",
    "\n",
    "mail id.:- **[mr.genius0180@gmail.com](https://)**\n",
    ">\n",
    ">\n",
    "guide:- **Intellipaat Trainer**\n",
    "\n",
    "Sponcerd:- **Intellipaat**\n",
    ">\n",
    ">\n",
    "Title:- **Case-Study NLP ML**\n",
    "\n",
    "Date:- **11/01/2025**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Problem Statement: `"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* After understanding the syntax of your text document, now, you need to extract features from the text \n",
    "document using various methods like bag-of-words, CountVectorizer, TermFrequency–Inverse Document \n",
    "Frequency (Tf–Idf). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **`Bag-of-words`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> **`Tasks:`**\n",
    "* Create a function named ‘tokenized_text ()’that takes ‘sentence’ as its argument and performs word tokenization and removes all stopwords \n",
    "* Create a function named ‘sorted_token ()’ that takes ‘sentence’ as its argument and removes the duplicate word tokens and returns a sorted list of word tokens \n",
    "* Create a function named ‘bag_of_word ()’ that takes ‘sentence’ and ‘word’ as its arguments, calculates the frequency word count of word tokens, and returns a NumPy array of word tokens \n",
    "* Create a bag-of-words model on the following sentences using the three functions defined above: \n",
    "     * Joe went to the store \n",
    "     * Joe wants to buy a dining set \n",
    "     * Joe met John at the store \n",
    "     * Joe and John are best friends \n",
    "* Convert the sentences into vectors using bag-of-words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function named ‘tokenized_text ()’that takes ‘sentence’ as its argument and performs \n",
    "# word tokenization and removes all stopwords\n",
    "\n",
    "def tokenized_text(sentence):\n",
    "    words = word_tokenize(sentence)\n",
    "    clean_text = [w.lower() for w in words if w not in stop_words]\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function named ‘sorted_token ()’ that takes ‘sentence’ as its argument and removes \n",
    "# the duplicate word tokens and returns a sorted list of word tokens \n",
    "\n",
    "def sorted_token(sentences):\n",
    "    words = []\n",
    "    for sentence in sentences:\n",
    "        clean_text = tokenized_text(sentence)\n",
    "        words.extend(clean_text)\n",
    "\n",
    "    words = sorted(list(set(words)))\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function named ‘bag_of_word ()’ that takes ‘sentence’ and ‘word’ as its arguments, \n",
    "# calculates the frequency word count of word tokens, and returns a NumPy array of word tokens\n",
    "\n",
    "def bag_of_word(sentence, words):\n",
    "    sentence_words = tokenized_text(sentence)\n",
    "\n",
    "    bag = np.zeros(len(words))\n",
    "    for sw in sentence_words:\n",
    "        for i, word in enumerate(words):\n",
    "            if word == sw:\n",
    "                bag[i] += 1\n",
    "\n",
    "    return np.array(bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a bag-of-words model on the following sentences using the three functions defined above: \n",
    "\n",
    "sentences = [\n",
    "    \"Joe went to the store\",\n",
    "    \"Joe wants to buy a dining set\",\n",
    "    \"Joe met John at the store\",\n",
    "    \"Joe and John are best friends\"\n",
    "]\n",
    "\n",
    "words = sorted_token(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_word('Joe and John are best friends', words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **`BOW using CountVectorizer`** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> `Tasks:`\n",
    "\n",
    "* Import ‘CountVectorizer’ from ‘sklearn.feature_extraction.text’ \n",
    "* Create a numpy array named ‘corpus’ that contains the following sentences: \n",
    "    * Joe went to the store \n",
    "    * Joe wants to buy a dining set \n",
    "    * Joe met John at the store \n",
    "    * Joe and John are best friends \n",
    "* Use the ‘CountVectorizer’ class object to fit and transform the text present in ‘corpus’ and \n",
    "store the result in ‘bag_of_words’ \n",
    "* Print ‘bag_of_words’ as a numpy array \n",
    "* Print all feature names of the above-created ‘CountVectorizer’ object \n",
    "* Print the ‘bag_of_words’ array as a Pandas Data Frame with column names as feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = np.array([\"Joe went to the store\",\n",
    "                \"Joe met John at the store\",\n",
    "                \"Joe wants to buy a dining set\",\n",
    "                \"Joe and John are best friends\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = cv.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1],\n",
       "       [0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0],\n",
       "       [0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0],\n",
       "       [1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = bow.toarray()\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['best', 'buy', 'dining', 'friends', 'joe', 'john', 'met', 'set',\n",
       "       'store', 'wants', 'went'], dtype=object)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = cv.get_feature_names_out()\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best</th>\n",
       "      <th>buy</th>\n",
       "      <th>dining</th>\n",
       "      <th>friends</th>\n",
       "      <th>joe</th>\n",
       "      <th>john</th>\n",
       "      <th>met</th>\n",
       "      <th>set</th>\n",
       "      <th>store</th>\n",
       "      <th>wants</th>\n",
       "      <th>went</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   best  buy  dining  friends  joe  john  met  set  store  wants  went\n",
       "0     0    0       0        0    1     0    0    0      1      0     1\n",
       "1     0    0       0        0    1     1    1    0      1      0     0\n",
       "2     0    1       1        0    1     0    0    1      0      1     0\n",
       "3     1    0       0        1    1     1    0    0      0      0     0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(vector, columns=feature_names)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **`Term Frequency–Inverse Document Frequency`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> `Tasks`\n",
    "* Import ‘TfidfVectorizer’ from ‘sklearn.feature_extraction.text’ \n",
    "* Create a numpy array named ‘corpus’ that contains the following sentences: \n",
    "    * Joe went to the store \n",
    "    * Joe wants to buy a dining set \n",
    "    * Joe met John at the store \n",
    "    * Joe and John are best friends \n",
    "* Use the ‘TfidfVectorizer’ class to create an object to fit and transform the text present in ‘corpus’ created above and store the result in ‘bag_of_words’ \n",
    "* Print ‘bag_of_words’ as a numpy array \n",
    "* Print all feature names of the above-created ‘TfidfVectorizer’ object \n",
    "* Print the ‘bag_of_words’ array as a pandas data frame with column names as feature names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = np.array([\"Joe went to the store\",\n",
    "                \"Joe met John at the store\",\n",
    "                \"Joe wants to buy a dining set\",\n",
    "                \"Joe and John are best friends\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words=\"english\")\n",
    "bow = tfidf.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.37919167,\n",
       "        0.        , 0.        , 0.        , 0.5728925 , 0.        ,\n",
       "        0.72664149],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.32902288,\n",
       "        0.4970962 , 0.6305035 , 0.        , 0.4970962 , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.48380259, 0.48380259, 0.        , 0.25246826,\n",
       "        0.        , 0.        , 0.48380259, 0.        , 0.48380259,\n",
       "        0.        ],\n",
       "       [0.58783765, 0.        , 0.        , 0.58783765, 0.30675807,\n",
       "        0.46345796, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = bow.toarray()\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['best', 'buy', 'dining', 'friends', 'joe', 'john', 'met', 'set',\n",
       "       'store', 'wants', 'went'], dtype=object)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = tfidf.get_feature_names_out()\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best</th>\n",
       "      <th>buy</th>\n",
       "      <th>dining</th>\n",
       "      <th>friends</th>\n",
       "      <th>joe</th>\n",
       "      <th>john</th>\n",
       "      <th>met</th>\n",
       "      <th>set</th>\n",
       "      <th>store</th>\n",
       "      <th>wants</th>\n",
       "      <th>went</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.379192</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.572892</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.726641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.329023</td>\n",
       "      <td>0.497096</td>\n",
       "      <td>0.630504</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.497096</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.483803</td>\n",
       "      <td>0.483803</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.252468</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.483803</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.483803</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.587838</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.587838</td>\n",
       "      <td>0.306758</td>\n",
       "      <td>0.463458</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       best       buy    dining  ...     store     wants      went\n",
       "0  0.000000  0.000000  0.000000  ...  0.572892  0.000000  0.726641\n",
       "1  0.000000  0.000000  0.000000  ...  0.497096  0.000000  0.000000\n",
       "2  0.000000  0.483803  0.483803  ...  0.000000  0.483803  0.000000\n",
       "3  0.587838  0.000000  0.000000  ...  0.000000  0.000000  0.000000\n",
       "\n",
       "[4 rows x 11 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(vector, columns=feature_names)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
