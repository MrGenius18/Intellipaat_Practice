{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[0.0], [0.01], [0.02], [0.03], [0.04]],\n",
       " [[0.01], [0.02], [0.03], [0.04], [0.05]],\n",
       " [[0.02], [0.03], [0.04], [0.05], [0.06]],\n",
       " [[0.03], [0.04], [0.05], [0.06], [0.07]],\n",
       " [[0.04], [0.05], [0.06], [0.07], [0.08]]]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data = [[[(i+j)/100] for i in range(5)] for j in range(100)]\n",
    "Data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.05, 0.06, 0.07, 0.08, 0.09]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Target = [(i+5)/100 for i in range(100)]\n",
    "Target[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(Data,dtype=float)\n",
    "target = np.array(Target,dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 5, 1), (100,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape, target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividing data into train & test\n",
    "x_train, x_test, y_train, y_test = train_test_split(data,target,test_size=0.2,random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RNN \n",
    "model = Sequential()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(LSTM((1),batch_input_shape=(None,5,1),return_sequences=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_absolute_error',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 1)                 12        \n",
      "=================================================================\n",
      "Total params: 12\n",
      "Trainable params: 12\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/500\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.6351 - acc: 0.0000e+00 - val_loss: 0.5077 - val_acc: 0.0000e+00\n",
      "Epoch 2/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.6316 - acc: 0.0000e+00 - val_loss: 0.5047 - val_acc: 0.0000e+00\n",
      "Epoch 3/500\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.6281 - acc: 0.0000e+00 - val_loss: 0.5018 - val_acc: 0.0000e+00\n",
      "Epoch 4/500\n",
      "80/80 [==============================] - 0s 225us/step - loss: 0.6247 - acc: 0.0000e+00 - val_loss: 0.4988 - val_acc: 0.0000e+00\n",
      "Epoch 5/500\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.6213 - acc: 0.0000e+00 - val_loss: 0.4959 - val_acc: 0.0000e+00\n",
      "Epoch 6/500\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.6180 - acc: 0.0000e+00 - val_loss: 0.4930 - val_acc: 0.0000e+00\n",
      "Epoch 7/500\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.6147 - acc: 0.0000e+00 - val_loss: 0.4901 - val_acc: 0.0000e+00\n",
      "Epoch 8/500\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.6114 - acc: 0.0000e+00 - val_loss: 0.4873 - val_acc: 0.0000e+00\n",
      "Epoch 9/500\n",
      "80/80 [==============================] - 0s 225us/step - loss: 0.6081 - acc: 0.0000e+00 - val_loss: 0.4845 - val_acc: 0.0000e+00\n",
      "Epoch 10/500\n",
      "80/80 [==============================] - 0s 263us/step - loss: 0.6049 - acc: 0.0000e+00 - val_loss: 0.4817 - val_acc: 0.0000e+00\n",
      "Epoch 11/500\n",
      "80/80 [==============================] - 0s 288us/step - loss: 0.6017 - acc: 0.0000e+00 - val_loss: 0.4789 - val_acc: 0.0000e+00\n",
      "Epoch 12/500\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.5985 - acc: 0.0000e+00 - val_loss: 0.4762 - val_acc: 0.0000e+00\n",
      "Epoch 13/500\n",
      "80/80 [==============================] - 0s 288us/step - loss: 0.5955 - acc: 0.0000e+00 - val_loss: 0.4735 - val_acc: 0.0000e+00\n",
      "Epoch 14/500\n",
      "80/80 [==============================] - 0s 263us/step - loss: 0.5924 - acc: 0.0000e+00 - val_loss: 0.4708 - val_acc: 0.0000e+00\n",
      "Epoch 15/500\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.5893 - acc: 0.0000e+00 - val_loss: 0.4682 - val_acc: 0.0000e+00\n",
      "Epoch 16/500\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.5863 - acc: 0.0000e+00 - val_loss: 0.4655 - val_acc: 0.0000e+00\n",
      "Epoch 17/500\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.5833 - acc: 0.0000e+00 - val_loss: 0.4629 - val_acc: 0.0000e+00\n",
      "Epoch 18/500\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.5803 - acc: 0.0000e+00 - val_loss: 0.4603 - val_acc: 0.0000e+00\n",
      "Epoch 19/500\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.5773 - acc: 0.0000e+00 - val_loss: 0.4577 - val_acc: 0.0000e+00\n",
      "Epoch 20/500\n",
      "80/80 [==============================] - 0s 225us/step - loss: 0.5744 - acc: 0.0000e+00 - val_loss: 0.4552 - val_acc: 0.0000e+00\n",
      "Epoch 21/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.5714 - acc: 0.0000e+00 - val_loss: 0.4526 - val_acc: 0.0000e+00\n",
      "Epoch 22/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.5685 - acc: 0.0000e+00 - val_loss: 0.4500 - val_acc: 0.0000e+00\n",
      "Epoch 23/500\n",
      "80/80 [==============================] - 0s 288us/step - loss: 0.5656 - acc: 0.0000e+00 - val_loss: 0.4475 - val_acc: 0.0000e+00\n",
      "Epoch 24/500\n",
      "80/80 [==============================] - 0s 225us/step - loss: 0.5627 - acc: 0.0000e+00 - val_loss: 0.4449 - val_acc: 0.0000e+00\n",
      "Epoch 25/500\n",
      "80/80 [==============================] - 0s 225us/step - loss: 0.5598 - acc: 0.0000e+00 - val_loss: 0.4424 - val_acc: 0.0000e+00\n",
      "Epoch 26/500\n",
      "80/80 [==============================] - 0s 263us/step - loss: 0.5570 - acc: 0.0000e+00 - val_loss: 0.4398 - val_acc: 0.0000e+00\n",
      "Epoch 27/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.5540 - acc: 0.0000e+00 - val_loss: 0.4372 - val_acc: 0.0000e+00\n",
      "Epoch 28/500\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.5511 - acc: 0.0000e+00 - val_loss: 0.4347 - val_acc: 0.0000e+00\n",
      "Epoch 29/500\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.5482 - acc: 0.0000e+00 - val_loss: 0.4320 - val_acc: 0.0000e+00\n",
      "Epoch 30/500\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.5452 - acc: 0.0000e+00 - val_loss: 0.4294 - val_acc: 0.0000e+00\n",
      "Epoch 31/500\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.5423 - acc: 0.0000e+00 - val_loss: 0.4268 - val_acc: 0.0000e+00\n",
      "Epoch 32/500\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.5393 - acc: 0.0000e+00 - val_loss: 0.4241 - val_acc: 0.0000e+00\n",
      "Epoch 33/500\n",
      "80/80 [==============================] - 0s 225us/step - loss: 0.5362 - acc: 0.0000e+00 - val_loss: 0.4214 - val_acc: 0.0000e+00\n",
      "Epoch 34/500\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.5332 - acc: 0.0000e+00 - val_loss: 0.4187 - val_acc: 0.0000e+00\n",
      "Epoch 35/500\n",
      "80/80 [==============================] - 0s 263us/step - loss: 0.5301 - acc: 0.0000e+00 - val_loss: 0.4159 - val_acc: 0.0000e+00\n",
      "Epoch 36/500\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.5270 - acc: 0.0000e+00 - val_loss: 0.4130 - val_acc: 0.0000e+00\n",
      "Epoch 37/500\n",
      "80/80 [==============================] - 0s 163us/step - loss: 0.5238 - acc: 0.0000e+00 - val_loss: 0.4101 - val_acc: 0.0000e+00\n",
      "Epoch 38/500\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.5205 - acc: 0.0000e+00 - val_loss: 0.4072 - val_acc: 0.0000e+00\n",
      "Epoch 39/500\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.5172 - acc: 0.0000e+00 - val_loss: 0.4042 - val_acc: 0.0000e+00\n",
      "Epoch 40/500\n",
      "80/80 [==============================] - 0s 263us/step - loss: 0.5138 - acc: 0.0000e+00 - val_loss: 0.4011 - val_acc: 0.0000e+00\n",
      "Epoch 41/500\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.5104 - acc: 0.0000e+00 - val_loss: 0.3979 - val_acc: 0.0000e+00\n",
      "Epoch 42/500\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.5069 - acc: 0.0000e+00 - val_loss: 0.3947 - val_acc: 0.0000e+00\n",
      "Epoch 43/500\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.5033 - acc: 0.0000e+00 - val_loss: 0.3914 - val_acc: 0.0000e+00\n",
      "Epoch 44/500\n",
      "80/80 [==============================] - 0s 225us/step - loss: 0.4997 - acc: 0.0000e+00 - val_loss: 0.3881 - val_acc: 0.0000e+00\n",
      "Epoch 45/500\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.4960 - acc: 0.0000e+00 - val_loss: 0.3847 - val_acc: 0.0000e+00\n",
      "Epoch 46/500\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.4923 - acc: 0.0000e+00 - val_loss: 0.3811 - val_acc: 0.0000e+00\n",
      "Epoch 47/500\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.4883 - acc: 0.0000e+00 - val_loss: 0.3777 - val_acc: 0.0000e+00\n",
      "Epoch 48/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.4844 - acc: 0.0000e+00 - val_loss: 0.3743 - val_acc: 0.0000e+00\n",
      "Epoch 49/500\n",
      "80/80 [==============================] - 0s 263us/step - loss: 0.4803 - acc: 0.0000e+00 - val_loss: 0.3707 - val_acc: 0.0000e+00\n",
      "Epoch 50/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.4762 - acc: 0.0000e+00 - val_loss: 0.3671 - val_acc: 0.0000e+00\n",
      "Epoch 51/500\n",
      "80/80 [==============================] - 0s 225us/step - loss: 0.4719 - acc: 0.0000e+00 - val_loss: 0.3633 - val_acc: 0.0000e+00\n",
      "Epoch 52/500\n",
      "80/80 [==============================] - 0s 263us/step - loss: 0.4675 - acc: 0.0000e+00 - val_loss: 0.3595 - val_acc: 0.0000e+00\n",
      "Epoch 53/500\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.4631 - acc: 0.0000e+00 - val_loss: 0.3556 - val_acc: 0.0000e+00\n",
      "Epoch 54/500\n",
      "80/80 [==============================] - 0s 225us/step - loss: 0.4585 - acc: 0.0000e+00 - val_loss: 0.3516 - val_acc: 0.0000e+00\n",
      "Epoch 55/500\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.4538 - acc: 0.0000e+00 - val_loss: 0.3475 - val_acc: 0.0000e+00\n",
      "Epoch 56/500\n",
      "80/80 [==============================] - 0s 150us/step - loss: 0.4492 - acc: 0.0000e+00 - val_loss: 0.3432 - val_acc: 0.0000e+00\n",
      "Epoch 57/500\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.4442 - acc: 0.0000e+00 - val_loss: 0.3389 - val_acc: 0.0000e+00\n",
      "Epoch 58/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 175us/step - loss: 0.4391 - acc: 0.0000e+00 - val_loss: 0.3345 - val_acc: 0.0000e+00\n",
      "Epoch 59/500\n",
      "80/80 [==============================] - 0s 263us/step - loss: 0.4341 - acc: 0.0000e+00 - val_loss: 0.3299 - val_acc: 0.0000e+00\n",
      "Epoch 60/500\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.4289 - acc: 0.0000e+00 - val_loss: 0.3253 - val_acc: 0.0000e+00\n",
      "Epoch 61/500\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.4236 - acc: 0.0000e+00 - val_loss: 0.3205 - val_acc: 0.0000e+00\n",
      "Epoch 62/500\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.4183 - acc: 0.0000e+00 - val_loss: 0.3156 - val_acc: 0.0000e+00\n",
      "Epoch 63/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.4127 - acc: 0.0000e+00 - val_loss: 0.3107 - val_acc: 0.0000e+00\n",
      "Epoch 64/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.4070 - acc: 0.0000e+00 - val_loss: 0.3056 - val_acc: 0.0000e+00\n",
      "Epoch 65/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.4015 - acc: 0.0000e+00 - val_loss: 0.3004 - val_acc: 0.0000e+00\n",
      "Epoch 66/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.3957 - acc: 0.0000e+00 - val_loss: 0.2951 - val_acc: 0.0000e+00\n",
      "Epoch 67/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.3898 - acc: 0.0000e+00 - val_loss: 0.2896 - val_acc: 0.0000e+00\n",
      "Epoch 68/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.3838 - acc: 0.0000e+00 - val_loss: 0.2841 - val_acc: 0.0000e+00\n",
      "Epoch 69/500\n",
      "80/80 [==============================] - 0s 225us/step - loss: 0.3778 - acc: 0.0000e+00 - val_loss: 0.2784 - val_acc: 0.0000e+00\n",
      "Epoch 70/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.3716 - acc: 0.0000e+00 - val_loss: 0.2727 - val_acc: 0.0000e+00\n",
      "Epoch 71/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.3654 - acc: 0.0000e+00 - val_loss: 0.2668 - val_acc: 0.0000e+00\n",
      "Epoch 72/500\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.3589 - acc: 0.0000e+00 - val_loss: 0.2611 - val_acc: 0.0000e+00\n",
      "Epoch 73/500\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.3526 - acc: 0.0000e+00 - val_loss: 0.2555 - val_acc: 0.0000e+00\n",
      "Epoch 74/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.3460 - acc: 0.0000e+00 - val_loss: 0.2497 - val_acc: 0.0000e+00\n",
      "Epoch 75/500\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.3395 - acc: 0.0000e+00 - val_loss: 0.2439 - val_acc: 0.0000e+00\n",
      "Epoch 76/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.3326 - acc: 0.0000e+00 - val_loss: 0.2379 - val_acc: 0.0000e+00\n",
      "Epoch 77/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.3262 - acc: 0.0000e+00 - val_loss: 0.2319 - val_acc: 0.0000e+00\n",
      "Epoch 78/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.3193 - acc: 0.0000e+00 - val_loss: 0.2259 - val_acc: 0.0000e+00\n",
      "Epoch 79/500\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.3123 - acc: 0.0000e+00 - val_loss: 0.2202 - val_acc: 0.0000e+00\n",
      "Epoch 80/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.3054 - acc: 0.0000e+00 - val_loss: 0.2146 - val_acc: 0.0000e+00\n",
      "Epoch 81/500\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.2982 - acc: 0.0000e+00 - val_loss: 0.2091 - val_acc: 0.0000e+00\n",
      "Epoch 82/500\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.2910 - acc: 0.0000e+00 - val_loss: 0.2035 - val_acc: 0.0000e+00\n",
      "Epoch 83/500\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.2809 - acc: 0.0000e+0 - 0s 200us/step - loss: 0.2836 - acc: 0.0000e+00 - val_loss: 0.1981 - val_acc: 0.0000e+00\n",
      "Epoch 84/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.2763 - acc: 0.0000e+00 - val_loss: 0.1931 - val_acc: 0.0000e+00\n",
      "Epoch 85/500\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.2692 - acc: 0.0000e+00 - val_loss: 0.1881 - val_acc: 0.0000e+00\n",
      "Epoch 86/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.2617 - acc: 0.0000e+00 - val_loss: 0.1830 - val_acc: 0.0000e+00\n",
      "Epoch 87/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.2545 - acc: 0.0000e+00 - val_loss: 0.1779 - val_acc: 0.0000e+00\n",
      "Epoch 88/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.2473 - acc: 0.0000e+00 - val_loss: 0.1728 - val_acc: 0.0500\n",
      "Epoch 89/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.2404 - acc: 0.0000e+00 - val_loss: 0.1683 - val_acc: 0.0500\n",
      "Epoch 90/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.2332 - acc: 0.0000e+00 - val_loss: 0.1639 - val_acc: 0.0500\n",
      "Epoch 91/500\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.2265 - acc: 0.0000e+00 - val_loss: 0.1594 - val_acc: 0.0500\n",
      "Epoch 92/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.2199 - acc: 0.0000e+00 - val_loss: 0.1550 - val_acc: 0.0500\n",
      "Epoch 93/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.2136 - acc: 0.0000e+00 - val_loss: 0.1508 - val_acc: 0.0500\n",
      "Epoch 94/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.2068 - acc: 0.0000e+00 - val_loss: 0.1472 - val_acc: 0.0500\n",
      "Epoch 95/500\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.2010 - acc: 0.0000e+00 - val_loss: 0.1436 - val_acc: 0.0500\n",
      "Epoch 96/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.1950 - acc: 0.0000e+00 - val_loss: 0.1405 - val_acc: 0.0500\n",
      "Epoch 97/500\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.1889 - acc: 0.0000e+00 - val_loss: 0.1375 - val_acc: 0.0500\n",
      "Epoch 98/500\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.1837 - acc: 0.0000e+00 - val_loss: 0.1348 - val_acc: 0.0500\n",
      "Epoch 99/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.1783 - acc: 0.0000e+00 - val_loss: 0.1325 - val_acc: 0.0500\n",
      "Epoch 100/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.1732 - acc: 0.0000e+00 - val_loss: 0.1304 - val_acc: 0.0500\n",
      "Epoch 101/500\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.1681 - acc: 0.0000e+00 - val_loss: 0.1282 - val_acc: 0.0500\n",
      "Epoch 102/500\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.1640 - acc: 0.0000e+00 - val_loss: 0.1262 - val_acc: 0.0500\n",
      "Epoch 103/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.1599 - acc: 0.0000e+00 - val_loss: 0.1242 - val_acc: 0.0500\n",
      "Epoch 104/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.1561 - acc: 0.0000e+00 - val_loss: 0.1227 - val_acc: 0.0500\n",
      "Epoch 105/500\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.1526 - acc: 0.0000e+00 - val_loss: 0.1215 - val_acc: 0.0500\n",
      "Epoch 106/500\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.1490 - acc: 0.0000e+00 - val_loss: 0.1207 - val_acc: 0.0500\n",
      "Epoch 107/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.1457 - acc: 0.0000e+00 - val_loss: 0.1200 - val_acc: 0.0500\n",
      "Epoch 108/500\n",
      "80/80 [==============================] - 0s 225us/step - loss: 0.1425 - acc: 0.0000e+00 - val_loss: 0.1194 - val_acc: 0.0500\n",
      "Epoch 109/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.1400 - acc: 0.0000e+00 - val_loss: 0.1188 - val_acc: 0.0500\n",
      "Epoch 110/500\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.1374 - acc: 0.0000e+00 - val_loss: 0.1187 - val_acc: 0.0500\n",
      "Epoch 111/500\n",
      "80/80 [==============================] - 0s 163us/step - loss: 0.1348 - acc: 0.0000e+00 - val_loss: 0.1188 - val_acc: 0.0500\n",
      "Epoch 112/500\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.1327 - acc: 0.0000e+00 - val_loss: 0.1191 - val_acc: 0.0500\n",
      "Epoch 113/500\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.1304 - acc: 0.0000e+00 - val_loss: 0.1194 - val_acc: 0.0500\n",
      "Epoch 114/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.1285 - acc: 0.0000e+00 - val_loss: 0.1196 - val_acc: 0.0500\n",
      "Epoch 115/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.1267 - acc: 0.0000e+00 - val_loss: 0.1199 - val_acc: 0.0500\n",
      "Epoch 116/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 213us/step - loss: 0.1251 - acc: 0.0000e+00 - val_loss: 0.1205 - val_acc: 0.0500\n",
      "Epoch 117/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.1236 - acc: 0.0000e+00 - val_loss: 0.1209 - val_acc: 0.0500\n",
      "Epoch 118/500\n",
      "80/80 [==============================] - 0s 163us/step - loss: 0.1223 - acc: 0.0000e+00 - val_loss: 0.1213 - val_acc: 0.0500\n",
      "Epoch 119/500\n",
      "80/80 [==============================] - 0s 225us/step - loss: 0.1212 - acc: 0.0000e+00 - val_loss: 0.1217 - val_acc: 0.0500\n",
      "Epoch 120/500\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.1197 - acc: 0.0000e+00 - val_loss: 0.1219 - val_acc: 0.0500\n",
      "Epoch 121/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.1188 - acc: 0.0000e+00 - val_loss: 0.1221 - val_acc: 0.0500\n",
      "Epoch 122/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.1175 - acc: 0.0000e+00 - val_loss: 0.1221 - val_acc: 0.0500\n",
      "Epoch 123/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.1167 - acc: 0.0000e+00 - val_loss: 0.1223 - val_acc: 0.0500\n",
      "Epoch 124/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.1158 - acc: 0.0000e+00 - val_loss: 0.1225 - val_acc: 0.0500\n",
      "Epoch 125/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.1149 - acc: 0.0000e+00 - val_loss: 0.1227 - val_acc: 0.0500\n",
      "Epoch 126/500\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.1139 - acc: 0.0000e+00 - val_loss: 0.1229 - val_acc: 0.0500\n",
      "Epoch 127/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.1130 - acc: 0.0000e+00 - val_loss: 0.1231 - val_acc: 0.0500\n",
      "Epoch 128/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.1121 - acc: 0.0000e+00 - val_loss: 0.1234 - val_acc: 0.0500\n",
      "Epoch 129/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.1113 - acc: 0.0000e+00 - val_loss: 0.1235 - val_acc: 0.0500\n",
      "Epoch 130/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.1105 - acc: 0.0000e+00 - val_loss: 0.1235 - val_acc: 0.0500\n",
      "Epoch 131/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.1096 - acc: 0.0000e+00 - val_loss: 0.1233 - val_acc: 0.0500\n",
      "Epoch 132/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.1089 - acc: 0.0000e+00 - val_loss: 0.1229 - val_acc: 0.0500\n",
      "Epoch 133/500\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.1080 - acc: 0.0000e+00 - val_loss: 0.1223 - val_acc: 0.0500\n",
      "Epoch 134/500\n",
      "80/80 [==============================] - 0s 325us/step - loss: 0.1073 - acc: 0.0000e+00 - val_loss: 0.1219 - val_acc: 0.0500\n",
      "Epoch 135/500\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.1065 - acc: 0.0000e+00 - val_loss: 0.1214 - val_acc: 0.0500\n",
      "Epoch 136/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.1057 - acc: 0.0000e+00 - val_loss: 0.1207 - val_acc: 0.0500\n",
      "Epoch 137/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.1049 - acc: 0.0000e+00 - val_loss: 0.1201 - val_acc: 0.0500\n",
      "Epoch 138/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.1042 - acc: 0.0000e+00 - val_loss: 0.1196 - val_acc: 0.0500\n",
      "Epoch 139/500\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.1034 - acc: 0.0000e+00 - val_loss: 0.1190 - val_acc: 0.0500\n",
      "Epoch 140/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.1026 - acc: 0.0000e+00 - val_loss: 0.1183 - val_acc: 0.0500\n",
      "Epoch 141/500\n",
      "80/80 [==============================] - 0s 163us/step - loss: 0.1019 - acc: 0.0000e+00 - val_loss: 0.1177 - val_acc: 0.0500\n",
      "Epoch 142/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.1011 - acc: 0.0000e+00 - val_loss: 0.1171 - val_acc: 0.0500\n",
      "Epoch 143/500\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.1004 - acc: 0.0000e+00 - val_loss: 0.1166 - val_acc: 0.0500\n",
      "Epoch 144/500\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.0996 - acc: 0.0000e+00 - val_loss: 0.1160 - val_acc: 0.0500\n",
      "Epoch 145/500\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.0989 - acc: 0.0000e+00 - val_loss: 0.1155 - val_acc: 0.0500\n",
      "Epoch 146/500\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.0981 - acc: 0.0000e+00 - val_loss: 0.1149 - val_acc: 0.0500\n",
      "Epoch 147/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0974 - acc: 0.0000e+00 - val_loss: 0.1143 - val_acc: 0.0500\n",
      "Epoch 148/500\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.0966 - acc: 0.0000e+00 - val_loss: 0.1136 - val_acc: 0.0500\n",
      "Epoch 149/500\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.0960 - acc: 0.0000e+00 - val_loss: 0.1131 - val_acc: 0.0500\n",
      "Epoch 150/500\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.0951 - acc: 0.0000e+00 - val_loss: 0.1124 - val_acc: 0.0500\n",
      "Epoch 151/500\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.0944 - acc: 0.0000e+00 - val_loss: 0.1117 - val_acc: 0.0500\n",
      "Epoch 152/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.0937 - acc: 0.0000e+00 - val_loss: 0.1109 - val_acc: 0.0500\n",
      "Epoch 153/500\n",
      "80/80 [==============================] - 0s 163us/step - loss: 0.0929 - acc: 0.0000e+00 - val_loss: 0.1102 - val_acc: 0.0500\n",
      "Epoch 154/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0922 - acc: 0.0000e+00 - val_loss: 0.1095 - val_acc: 0.0500\n",
      "Epoch 155/500\n",
      "80/80 [==============================] - 0s 163us/step - loss: 0.0915 - acc: 0.0000e+00 - val_loss: 0.1088 - val_acc: 0.0500\n",
      "Epoch 156/500\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.0908 - acc: 0.0000e+00 - val_loss: 0.1080 - val_acc: 0.0500\n",
      "Epoch 157/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0900 - acc: 0.0000e+00 - val_loss: 0.1072 - val_acc: 0.0500\n",
      "Epoch 158/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0893 - acc: 0.0000e+00 - val_loss: 0.1067 - val_acc: 0.0500\n",
      "Epoch 159/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0886 - acc: 0.0000e+00 - val_loss: 0.1059 - val_acc: 0.0500\n",
      "Epoch 160/500\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.0879 - acc: 0.0000e+00 - val_loss: 0.1052 - val_acc: 0.0500\n",
      "Epoch 161/500\n",
      "80/80 [==============================] - 0s 225us/step - loss: 0.0871 - acc: 0.0000e+00 - val_loss: 0.1046 - val_acc: 0.0500\n",
      "Epoch 162/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.0864 - acc: 0.0000e+00 - val_loss: 0.1039 - val_acc: 0.0500\n",
      "Epoch 163/500\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.0857 - acc: 0.0000e+00 - val_loss: 0.1033 - val_acc: 0.0500\n",
      "Epoch 164/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.0850 - acc: 0.0000e+00 - val_loss: 0.1027 - val_acc: 0.0500\n",
      "Epoch 165/500\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.0842 - acc: 0.0000e+00 - val_loss: 0.1020 - val_acc: 0.0500\n",
      "Epoch 166/500\n",
      "80/80 [==============================] - 0s 163us/step - loss: 0.0835 - acc: 0.0000e+00 - val_loss: 0.1012 - val_acc: 0.0500\n",
      "Epoch 167/500\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.0828 - acc: 0.0000e+00 - val_loss: 0.1004 - val_acc: 0.0500\n",
      "Epoch 168/500\n",
      "80/80 [==============================] - 0s 150us/step - loss: 0.0820 - acc: 0.0000e+00 - val_loss: 0.0995 - val_acc: 0.0500\n",
      "Epoch 169/500\n",
      "80/80 [==============================] - 0s 163us/step - loss: 0.0814 - acc: 0.0000e+00 - val_loss: 0.0986 - val_acc: 0.0500\n",
      "Epoch 170/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0806 - acc: 0.0000e+00 - val_loss: 0.0978 - val_acc: 0.0500\n",
      "Epoch 171/500\n",
      "80/80 [==============================] - 0s 225us/step - loss: 0.0798 - acc: 0.0000e+00 - val_loss: 0.0971 - val_acc: 0.0500\n",
      "Epoch 172/500\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.0791 - acc: 0.0000e+00 - val_loss: 0.0963 - val_acc: 0.0500\n",
      "Epoch 173/500\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.0784 - acc: 0.0000e+00 - val_loss: 0.0957 - val_acc: 0.0500\n",
      "Epoch 174/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0777 - acc: 0.0000e+00 - val_loss: 0.0951 - val_acc: 0.0500\n",
      "Epoch 175/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 188us/step - loss: 0.0769 - acc: 0.0000e+00 - val_loss: 0.0944 - val_acc: 0.0500\n",
      "Epoch 176/500\n",
      "80/80 [==============================] - 0s 163us/step - loss: 0.0761 - acc: 0.0000e+00 - val_loss: 0.0934 - val_acc: 0.0500\n",
      "Epoch 177/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0754 - acc: 0.0000e+00 - val_loss: 0.0923 - val_acc: 0.0500\n",
      "Epoch 178/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0747 - acc: 0.0000e+00 - val_loss: 0.0914 - val_acc: 0.0500\n",
      "Epoch 179/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.0739 - acc: 0.0000e+00 - val_loss: 0.0905 - val_acc: 0.0500\n",
      "Epoch 180/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0732 - acc: 0.0000e+00 - val_loss: 0.0895 - val_acc: 0.0500\n",
      "Epoch 181/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0725 - acc: 0.0000e+00 - val_loss: 0.0886 - val_acc: 0.0500\n",
      "Epoch 182/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0717 - acc: 0.0000e+00 - val_loss: 0.0879 - val_acc: 0.0500\n",
      "Epoch 183/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.0710 - acc: 0.0000e+00 - val_loss: 0.0871 - val_acc: 0.0500\n",
      "Epoch 184/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.0702 - acc: 0.0000e+00 - val_loss: 0.0864 - val_acc: 0.0500\n",
      "Epoch 185/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.0695 - acc: 0.0000e+00 - val_loss: 0.0860 - val_acc: 0.0500\n",
      "Epoch 186/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.0687 - acc: 0.0000e+00 - val_loss: 0.0855 - val_acc: 0.0500\n",
      "Epoch 187/500\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.0680 - acc: 0.0000e+00 - val_loss: 0.0848 - val_acc: 0.0500\n",
      "Epoch 188/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0673 - acc: 0.0000e+00 - val_loss: 0.0840 - val_acc: 0.0500\n",
      "Epoch 189/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0666 - acc: 0.0000e+00 - val_loss: 0.0832 - val_acc: 0.0500\n",
      "Epoch 190/500\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.0660 - acc: 0.0000e+00 - val_loss: 0.0826 - val_acc: 0.0500\n",
      "Epoch 191/500\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.0652 - acc: 0.0000e+00 - val_loss: 0.0818 - val_acc: 0.0500\n",
      "Epoch 192/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0645 - acc: 0.0000e+00 - val_loss: 0.0811 - val_acc: 0.0500\n",
      "Epoch 193/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0638 - acc: 0.0000e+00 - val_loss: 0.0802 - val_acc: 0.0500\n",
      "Epoch 194/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0631 - acc: 0.0000e+00 - val_loss: 0.0794 - val_acc: 0.0500\n",
      "Epoch 195/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.0625 - acc: 0.0000e+00 - val_loss: 0.0786 - val_acc: 0.0500\n",
      "Epoch 196/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0618 - acc: 0.0000e+00 - val_loss: 0.0776 - val_acc: 0.0500\n",
      "Epoch 197/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0611 - acc: 0.0000e+00 - val_loss: 0.0770 - val_acc: 0.0500\n",
      "Epoch 198/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0604 - acc: 0.0000e+00 - val_loss: 0.0765 - val_acc: 0.0500\n",
      "Epoch 199/500\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.0598 - acc: 0.0000e+00 - val_loss: 0.0758 - val_acc: 0.0500\n",
      "Epoch 200/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0591 - acc: 0.0000e+00 - val_loss: 0.0753 - val_acc: 0.0500\n",
      "Epoch 201/500\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.0585 - acc: 0.0000e+00 - val_loss: 0.0748 - val_acc: 0.0500\n",
      "Epoch 202/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0578 - acc: 0.0000e+00 - val_loss: 0.0745 - val_acc: 0.0500\n",
      "Epoch 203/500\n",
      "80/80 [==============================] - 0s 163us/step - loss: 0.0572 - acc: 0.0000e+00 - val_loss: 0.0743 - val_acc: 0.0500\n",
      "Epoch 204/500\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.0567 - acc: 0.0000e+00 - val_loss: 0.0740 - val_acc: 0.0500\n",
      "Epoch 205/500\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.0561 - acc: 0.0000e+00 - val_loss: 0.0734 - val_acc: 0.0500\n",
      "Epoch 206/500\n",
      "80/80 [==============================] - 0s 225us/step - loss: 0.0555 - acc: 0.0000e+00 - val_loss: 0.0722 - val_acc: 0.0500\n",
      "Epoch 207/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0548 - acc: 0.0000e+00 - val_loss: 0.0710 - val_acc: 0.0500\n",
      "Epoch 208/500\n",
      "80/80 [==============================] - 0s 150us/step - loss: 0.0542 - acc: 0.0000e+00 - val_loss: 0.0699 - val_acc: 0.0500\n",
      "Epoch 209/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0536 - acc: 0.0000e+00 - val_loss: 0.0690 - val_acc: 0.0500\n",
      "Epoch 210/500\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.0530 - acc: 0.0000e+00 - val_loss: 0.0681 - val_acc: 0.0500\n",
      "Epoch 211/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0524 - acc: 0.0000e+00 - val_loss: 0.0675 - val_acc: 0.0500\n",
      "Epoch 212/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0518 - acc: 0.0000e+00 - val_loss: 0.0671 - val_acc: 0.0500\n",
      "Epoch 213/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0512 - acc: 0.0000e+00 - val_loss: 0.0667 - val_acc: 0.0500\n",
      "Epoch 214/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0506 - acc: 0.0000e+00 - val_loss: 0.0661 - val_acc: 0.0500\n",
      "Epoch 215/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0500 - acc: 0.0000e+00 - val_loss: 0.0652 - val_acc: 0.0500\n",
      "Epoch 216/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0494 - acc: 0.0000e+00 - val_loss: 0.0645 - val_acc: 0.0500\n",
      "Epoch 217/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0489 - acc: 0.0000e+00 - val_loss: 0.0636 - val_acc: 0.0500\n",
      "Epoch 218/500\n",
      "80/80 [==============================] - 0s 225us/step - loss: 0.0483 - acc: 0.0000e+00 - val_loss: 0.0630 - val_acc: 0.0500\n",
      "Epoch 219/500\n",
      "80/80 [==============================] - 0s 163us/step - loss: 0.0477 - acc: 0.0000e+00 - val_loss: 0.0623 - val_acc: 0.0500\n",
      "Epoch 220/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0471 - acc: 0.0000e+00 - val_loss: 0.0616 - val_acc: 0.0500\n",
      "Epoch 221/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.0465 - acc: 0.0000e+00 - val_loss: 0.0610 - val_acc: 0.0500\n",
      "Epoch 222/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.0459 - acc: 0.0000e+00 - val_loss: 0.0602 - val_acc: 0.0500\n",
      "Epoch 223/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0453 - acc: 0.0000e+00 - val_loss: 0.0597 - val_acc: 0.0500\n",
      "Epoch 224/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0447 - acc: 0.0000e+00 - val_loss: 0.0591 - val_acc: 0.0500\n",
      "Epoch 225/500\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.0442 - acc: 0.0000e+00 - val_loss: 0.0584 - val_acc: 0.0500\n",
      "Epoch 226/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.0436 - acc: 0.0000e+00 - val_loss: 0.0577 - val_acc: 0.0500\n",
      "Epoch 227/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.0430 - acc: 0.0000e+00 - val_loss: 0.0571 - val_acc: 0.0500\n",
      "Epoch 228/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0424 - acc: 0.0000e+00 - val_loss: 0.0565 - val_acc: 0.0500\n",
      "Epoch 229/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0418 - acc: 0.0000e+00 - val_loss: 0.0558 - val_acc: 0.0500\n",
      "Epoch 230/500\n",
      "80/80 [==============================] - 0s 225us/step - loss: 0.0412 - acc: 0.0000e+00 - val_loss: 0.0549 - val_acc: 0.0500\n",
      "Epoch 231/500\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.0406 - acc: 0.0000e+00 - val_loss: 0.0540 - val_acc: 0.0500\n",
      "Epoch 232/500\n",
      "80/80 [==============================] - 0s 163us/step - loss: 0.0400 - acc: 0.0000e+00 - val_loss: 0.0530 - val_acc: 0.0500\n",
      "Epoch 233/500\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.0395 - acc: 0.0000e+00 - val_loss: 0.0522 - val_acc: 0.0500\n",
      "Epoch 234/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 188us/step - loss: 0.0389 - acc: 0.0000e+00 - val_loss: 0.0517 - val_acc: 0.0500\n",
      "Epoch 235/500\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.0382 - acc: 0.0000e+00 - val_loss: 0.0511 - val_acc: 0.0500\n",
      "Epoch 236/500\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.0376 - acc: 0.0000e+00 - val_loss: 0.0505 - val_acc: 0.0500\n",
      "Epoch 237/500\n",
      "80/80 [==============================] - 0s 225us/step - loss: 0.0370 - acc: 0.0000e+00 - val_loss: 0.0499 - val_acc: 0.0500\n",
      "Epoch 238/500\n",
      "80/80 [==============================] - 0s 288us/step - loss: 0.0364 - acc: 0.0000e+00 - val_loss: 0.0492 - val_acc: 0.0500\n",
      "Epoch 239/500\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.0358 - acc: 0.0000e+00 - val_loss: 0.0485 - val_acc: 0.0500\n",
      "Epoch 240/500\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.0352 - acc: 0.0000e+00 - val_loss: 0.0476 - val_acc: 0.0500\n",
      "Epoch 241/500\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.0346 - acc: 0.0000e+00 - val_loss: 0.0470 - val_acc: 0.0500\n",
      "Epoch 242/500\n",
      "80/80 [==============================] - 0s 225us/step - loss: 0.0340 - acc: 0.0000e+00 - val_loss: 0.0465 - val_acc: 0.0500\n",
      "Epoch 243/500\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.0334 - acc: 0.0000e+00 - val_loss: 0.0454 - val_acc: 0.0500\n",
      "Epoch 244/500\n",
      "80/80 [==============================] - 0s 263us/step - loss: 0.0327 - acc: 0.0000e+00 - val_loss: 0.0445 - val_acc: 0.0500\n",
      "Epoch 245/500\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.0322 - acc: 0.0000e+00 - val_loss: 0.0438 - val_acc: 0.0500\n",
      "Epoch 246/500\n",
      "80/80 [==============================] - 0s 225us/step - loss: 0.0315 - acc: 0.0000e+00 - val_loss: 0.0434 - val_acc: 0.0500\n",
      "Epoch 247/500\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.0310 - acc: 0.0000e+00 - val_loss: 0.0424 - val_acc: 0.0500\n",
      "Epoch 248/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0304 - acc: 0.0000e+00 - val_loss: 0.0418 - val_acc: 0.0500\n",
      "Epoch 249/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0299 - acc: 0.0000e+00 - val_loss: 0.0409 - val_acc: 0.0500\n",
      "Epoch 250/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.0294 - acc: 0.0000e+00 - val_loss: 0.0405 - val_acc: 0.0500\n",
      "Epoch 251/500\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.0289 - acc: 0.0000e+00 - val_loss: 0.0397 - val_acc: 0.0500\n",
      "Epoch 252/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0285 - acc: 0.0000e+00 - val_loss: 0.0391 - val_acc: 0.0500\n",
      "Epoch 253/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.0281 - acc: 0.0000e+00 - val_loss: 0.0387 - val_acc: 0.0500\n",
      "Epoch 254/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.0278 - acc: 0.0000e+00 - val_loss: 0.0381 - val_acc: 0.0500\n",
      "Epoch 255/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0275 - acc: 0.0000e+00 - val_loss: 0.0376 - val_acc: 0.0500\n",
      "Epoch 256/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.0271 - acc: 0.0000e+00 - val_loss: 0.0372 - val_acc: 0.0500\n",
      "Epoch 257/500\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.0268 - acc: 0.0000e+00 - val_loss: 0.0368 - val_acc: 0.0500\n",
      "Epoch 258/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0266 - acc: 0.0000e+00 - val_loss: 0.0364 - val_acc: 0.0500\n",
      "Epoch 259/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0263 - acc: 0.0000e+00 - val_loss: 0.0361 - val_acc: 0.0500\n",
      "Epoch 260/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0260 - acc: 0.0000e+00 - val_loss: 0.0358 - val_acc: 0.0500\n",
      "Epoch 261/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0258 - acc: 0.0000e+00 - val_loss: 0.0354 - val_acc: 0.0500\n",
      "Epoch 262/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0255 - acc: 0.0000e+00 - val_loss: 0.0351 - val_acc: 0.0500\n",
      "Epoch 263/500\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.0253 - acc: 0.0000e+00 - val_loss: 0.0348 - val_acc: 0.0500\n",
      "Epoch 264/500\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.0251 - acc: 0.0000e+00 - val_loss: 0.0344 - val_acc: 0.0500\n",
      "Epoch 265/500\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.0249 - acc: 0.0000e+00 - val_loss: 0.0342 - val_acc: 0.0500\n",
      "Epoch 266/500\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.0247 - acc: 0.0000e+00 - val_loss: 0.0340 - val_acc: 0.0500\n",
      "Epoch 267/500\n",
      "80/80 [==============================] - 0s 225us/step - loss: 0.0245 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0500\n",
      "Epoch 268/500\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.0242 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0500\n",
      "Epoch 269/500\n",
      "80/80 [==============================] - 0s 163us/step - loss: 0.0242 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0500\n",
      "Epoch 270/500\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.0239 - acc: 0.0000e+00 - val_loss: 0.0329 - val_acc: 0.0500\n",
      "Epoch 271/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0237 - acc: 0.0000e+00 - val_loss: 0.0328 - val_acc: 0.0500\n",
      "Epoch 272/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.0235 - acc: 0.0000e+00 - val_loss: 0.0327 - val_acc: 0.0500\n",
      "Epoch 273/500\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.0233 - acc: 0.0000e+00 - val_loss: 0.0323 - val_acc: 0.0500\n",
      "Epoch 274/500\n",
      "80/80 [==============================] - 0s 150us/step - loss: 0.0231 - acc: 0.0000e+00 - val_loss: 0.0320 - val_acc: 0.0500\n",
      "Epoch 275/500\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.0230 - acc: 0.0000e+00 - val_loss: 0.0318 - val_acc: 0.0500\n",
      "Epoch 276/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.0228 - acc: 0.0000e+00 - val_loss: 0.0316 - val_acc: 0.0500\n",
      "Epoch 277/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0226 - acc: 0.0000e+00 - val_loss: 0.0316 - val_acc: 0.0500\n",
      "Epoch 278/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.0224 - acc: 0.0000e+00 - val_loss: 0.0314 - val_acc: 0.0500\n",
      "Epoch 279/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0223 - acc: 0.0000e+00 - val_loss: 0.0313 - val_acc: 0.0500\n",
      "Epoch 280/500\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.0221 - acc: 0.0000e+00 - val_loss: 0.0309 - val_acc: 0.0500\n",
      "Epoch 281/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0220 - acc: 0.0000e+00 - val_loss: 0.0306 - val_acc: 0.0500\n",
      "Epoch 282/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0219 - acc: 0.0000e+00 - val_loss: 0.0304 - val_acc: 0.0500\n",
      "Epoch 283/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.0217 - acc: 0.0000e+00 - val_loss: 0.0304 - val_acc: 0.0500\n",
      "Epoch 284/500\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.0216 - acc: 0.0000e+00 - val_loss: 0.0304 - val_acc: 0.0500\n",
      "Epoch 285/500\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.0214 - acc: 0.0000e+00 - val_loss: 0.0300 - val_acc: 0.0500\n",
      "Epoch 286/500\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.0213 - acc: 0.0000e+00 - val_loss: 0.0298 - val_acc: 0.0500\n",
      "Epoch 287/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0212 - acc: 0.0000e+00 - val_loss: 0.0296 - val_acc: 0.0500\n",
      "Epoch 288/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0210 - acc: 0.0000e+00 - val_loss: 0.0295 - val_acc: 0.0500\n",
      "Epoch 289/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0209 - acc: 0.0000e+00 - val_loss: 0.0294 - val_acc: 0.0500\n",
      "Epoch 290/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.0208 - acc: 0.0000e+00 - val_loss: 0.0293 - val_acc: 0.0500\n",
      "Epoch 291/500\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.0207 - acc: 0.0000e+00 - val_loss: 0.0291 - val_acc: 0.0500\n",
      "Epoch 292/500\n",
      "80/80 [==============================] - 0s 163us/step - loss: 0.0205 - acc: 0.0000e+00 - val_loss: 0.0290 - val_acc: 0.0500\n",
      "Epoch 293/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 200us/step - loss: 0.0204 - acc: 0.0000e+00 - val_loss: 0.0289 - val_acc: 0.0500\n",
      "Epoch 294/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0203 - acc: 0.0000e+00 - val_loss: 0.0286 - val_acc: 0.0500\n",
      "Epoch 295/500\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.0202 - acc: 0.0000e+00 - val_loss: 0.0284 - val_acc: 0.0500\n",
      "Epoch 296/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0201 - acc: 0.0000e+00 - val_loss: 0.0283 - val_acc: 0.0500\n",
      "Epoch 297/500\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.0200 - acc: 0.0000e+00 - val_loss: 0.0282 - val_acc: 0.0500\n",
      "Epoch 298/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.0199 - acc: 0.0000e+00 - val_loss: 0.0280 - val_acc: 0.0500\n",
      "Epoch 299/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.0198 - acc: 0.0000e+00 - val_loss: 0.0279 - val_acc: 0.0500\n",
      "Epoch 300/500\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.0197 - acc: 0.0000e+00 - val_loss: 0.0277 - val_acc: 0.0500\n",
      "Epoch 301/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.0196 - acc: 0.0000e+00 - val_loss: 0.0276 - val_acc: 0.0500\n",
      "Epoch 302/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0195 - acc: 0.0000e+00 - val_loss: 0.0275 - val_acc: 0.0500\n",
      "Epoch 303/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.0194 - acc: 0.0000e+00 - val_loss: 0.0274 - val_acc: 0.0500\n",
      "Epoch 304/500\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.0193 - acc: 0.0000e+00 - val_loss: 0.0273 - val_acc: 0.0500\n",
      "Epoch 305/500\n",
      "80/80 [==============================] - 0s 225us/step - loss: 0.0192 - acc: 0.0000e+00 - val_loss: 0.0272 - val_acc: 0.0500\n",
      "Epoch 306/500\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.0192 - acc: 0.0000e+00 - val_loss: 0.0270 - val_acc: 0.0500\n",
      "Epoch 307/500\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.0191 - acc: 0.0000e+00 - val_loss: 0.0269 - val_acc: 0.0500\n",
      "Epoch 308/500\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.0190 - acc: 0.0000e+00 - val_loss: 0.0268 - val_acc: 0.0500\n",
      "Epoch 309/500\n",
      "80/80 [==============================] - 0s 225us/step - loss: 0.0189 - acc: 0.0000e+00 - val_loss: 0.0266 - val_acc: 0.0500\n",
      "Epoch 310/500\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.0188 - acc: 0.0000e+00 - val_loss: 0.0264 - val_acc: 0.0500\n",
      "Epoch 311/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.0188 - acc: 0.0000e+00 - val_loss: 0.0263 - val_acc: 0.0500\n",
      "Epoch 312/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0187 - acc: 0.0000e+00 - val_loss: 0.0262 - val_acc: 0.0500\n",
      "Epoch 313/500\n",
      "80/80 [==============================] - 0s 225us/step - loss: 0.0186 - acc: 0.0000e+00 - val_loss: 0.0261 - val_acc: 0.0500\n",
      "Epoch 314/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0185 - acc: 0.0000e+00 - val_loss: 0.0261 - val_acc: 0.0500\n",
      "Epoch 315/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.0185 - acc: 0.0000e+00 - val_loss: 0.0260 - val_acc: 0.0500\n",
      "Epoch 316/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.0184 - acc: 0.0000e+00 - val_loss: 0.0258 - val_acc: 0.0500\n",
      "Epoch 317/500\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.0183 - acc: 0.0000e+00 - val_loss: 0.0256 - val_acc: 0.0500\n",
      "Epoch 318/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.0183 - acc: 0.0000e+00 - val_loss: 0.0255 - val_acc: 0.0500\n",
      "Epoch 319/500\n",
      "80/80 [==============================] - 0s 375us/step - loss: 0.0182 - acc: 0.0000e+00 - val_loss: 0.0255 - val_acc: 0.0500\n",
      "Epoch 320/500\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.0181 - acc: 0.0000e+00 - val_loss: 0.0255 - val_acc: 0.0500\n",
      "Epoch 321/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.0181 - acc: 0.0000e+00 - val_loss: 0.0254 - val_acc: 0.0500\n",
      "Epoch 322/500\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.0181 - acc: 0.0000e+00 - val_loss: 0.0252 - val_acc: 0.0500\n",
      "Epoch 323/500\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.0179 - acc: 0.0000e+00 - val_loss: 0.0251 - val_acc: 0.0500\n",
      "Epoch 324/500\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.0179 - acc: 0.0000e+00 - val_loss: 0.0249 - val_acc: 0.0500\n",
      "Epoch 325/500\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.0178 - acc: 0.0000e+00 - val_loss: 0.0249 - val_acc: 0.0500\n",
      "Epoch 326/500\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.0178 - acc: 0.0000e+00 - val_loss: 0.0249 - val_acc: 0.0500\n",
      "Epoch 327/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0177 - acc: 0.0000e+00 - val_loss: 0.0247 - val_acc: 0.0500\n",
      "Epoch 328/500\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.0176 - acc: 0.0000e+00 - val_loss: 0.0246 - val_acc: 0.0500\n",
      "Epoch 329/500\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.0176 - acc: 0.0000e+00 - val_loss: 0.0245 - val_acc: 0.0500\n",
      "Epoch 330/500\n",
      "80/80 [==============================] - 0s 225us/step - loss: 0.0175 - acc: 0.0000e+00 - val_loss: 0.0244 - val_acc: 0.0500\n",
      "Epoch 331/500\n",
      "80/80 [==============================] - 0s 225us/step - loss: 0.0174 - acc: 0.0000e+00 - val_loss: 0.0243 - val_acc: 0.0500\n",
      "Epoch 332/500\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.0174 - acc: 0.0000e+00 - val_loss: 0.0242 - val_acc: 0.0500\n",
      "Epoch 333/500\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.0174 - acc: 0.0000e+00 - val_loss: 0.0242 - val_acc: 0.0500\n",
      "Epoch 334/500\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.0173 - acc: 0.0000e+00 - val_loss: 0.0240 - val_acc: 0.0500\n",
      "Epoch 335/500\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.0173 - acc: 0.0000e+00 - val_loss: 0.0238 - val_acc: 0.0500\n",
      "Epoch 336/500\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.0172 - acc: 0.0000e+00 - val_loss: 0.0237 - val_acc: 0.0500\n",
      "Epoch 337/500\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.0172 - acc: 0.0000e+00 - val_loss: 0.0237 - val_acc: 0.0500\n",
      "Epoch 338/500\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.0171 - acc: 0.0000e+00 - val_loss: 0.0238 - val_acc: 0.0500\n",
      "Epoch 339/500\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.0171 - acc: 0.0000e+00 - val_loss: 0.0238 - val_acc: 0.0500\n",
      "Epoch 340/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.0171 - acc: 0.0000e+00 - val_loss: 0.0236 - val_acc: 0.0500\n",
      "Epoch 341/500\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.0170 - acc: 0.0000e+00 - val_loss: 0.0234 - val_acc: 0.0500\n",
      "Epoch 342/500\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.0169 - acc: 0.0000e+00 - val_loss: 0.0232 - val_acc: 0.0500\n",
      "Epoch 343/500\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.0169 - acc: 0.0000e+00 - val_loss: 0.0231 - val_acc: 0.0500\n",
      "Epoch 344/500\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.0169 - acc: 0.0000e+00 - val_loss: 0.0231 - val_acc: 0.0500\n",
      "Epoch 345/500\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.0168 - acc: 0.0000e+00 - val_loss: 0.0231 - val_acc: 0.0500\n",
      "Epoch 346/500\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.0168 - acc: 0.0000e+00 - val_loss: 0.0231 - val_acc: 0.0500\n",
      "Epoch 347/500\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.0167 - acc: 0.0000e+00 - val_loss: 0.0231 - val_acc: 0.0500\n",
      "Epoch 348/500\n",
      "80/80 [==============================] - 0s 263us/step - loss: 0.0167 - acc: 0.0000e+00 - val_loss: 0.0231 - val_acc: 0.0500\n",
      "Epoch 349/500\n",
      "80/80 [==============================] - 0s 225us/step - loss: 0.0167 - acc: 0.0000e+00 - val_loss: 0.0230 - val_acc: 0.0500\n",
      "Epoch 350/500\n",
      "80/80 [==============================] - 0s 225us/step - loss: 0.0166 - acc: 0.0000e+00 - val_loss: 0.0227 - val_acc: 0.0500\n",
      "Epoch 351/500\n",
      "80/80 [==============================] - 0s 225us/step - loss: 0.0166 - acc: 0.0000e+00 - val_loss: 0.0225 - val_acc: 0.0500\n",
      "Epoch 352/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 225us/step - loss: 0.0166 - acc: 0.0000e+00 - val_loss: 0.0224 - val_acc: 0.0500\n",
      "Epoch 353/500\n",
      "80/80 [==============================] - 0s 163us/step - loss: 0.0166 - acc: 0.0000e+00 - val_loss: 0.0225 - val_acc: 0.0500\n",
      "Epoch 354/500\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.0165 - acc: 0.0000e+00 - val_loss: 0.0226 - val_acc: 0.0500\n",
      "Epoch 355/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.0164 - acc: 0.0000e+00 - val_loss: 0.0226 - val_acc: 0.0500\n",
      "Epoch 356/500\n",
      "80/80 [==============================] - 0s 225us/step - loss: 0.0164 - acc: 0.0000e+00 - val_loss: 0.0225 - val_acc: 0.0500\n",
      "Epoch 357/500\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.0164 - acc: 0.0000e+00 - val_loss: 0.0223 - val_acc: 0.0500\n",
      "Epoch 358/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0164 - acc: 0.0000e+00 - val_loss: 0.0222 - val_acc: 0.0500\n",
      "Epoch 359/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0163 - acc: 0.0000e+00 - val_loss: 0.0221 - val_acc: 0.0500\n",
      "Epoch 360/500\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.0163 - acc: 0.0000e+00 - val_loss: 0.0221 - val_acc: 0.0500\n",
      "Epoch 361/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0163 - acc: 0.0000e+00 - val_loss: 0.0221 - val_acc: 0.0500\n",
      "Epoch 362/500\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.0162 - acc: 0.0000e+00 - val_loss: 0.0222 - val_acc: 0.0500\n",
      "Epoch 363/500\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.0162 - acc: 0.0000e+00 - val_loss: 0.0222 - val_acc: 0.0500\n",
      "Epoch 364/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.0162 - acc: 0.0000e+00 - val_loss: 0.0221 - val_acc: 0.0500\n",
      "Epoch 365/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.0161 - acc: 0.0000e+00 - val_loss: 0.0218 - val_acc: 0.0500\n",
      "Epoch 366/500\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.0161 - acc: 0.0000e+00 - val_loss: 0.0217 - val_acc: 0.0500\n",
      "Epoch 367/500\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.0161 - acc: 0.0000e+00 - val_loss: 0.0216 - val_acc: 0.0500\n",
      "Epoch 368/500\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.0161 - acc: 0.0000e+00 - val_loss: 0.0217 - val_acc: 0.0500\n",
      "Epoch 369/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.0160 - acc: 0.0000e+00 - val_loss: 0.0219 - val_acc: 0.0500\n",
      "Epoch 370/500\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.0160 - acc: 0.0000e+00 - val_loss: 0.0220 - val_acc: 0.0500\n",
      "Epoch 371/500\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.0161 - acc: 0.0000e+00 - val_loss: 0.0221 - val_acc: 0.0500\n",
      "Epoch 372/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.0161 - acc: 0.0000e+00 - val_loss: 0.0218 - val_acc: 0.0500\n",
      "Epoch 373/500\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.0159 - acc: 0.0000e+00 - val_loss: 0.0214 - val_acc: 0.0500\n",
      "Epoch 374/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.0159 - acc: 0.0000e+00 - val_loss: 0.0211 - val_acc: 0.0500\n",
      "Epoch 375/500\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.0160 - acc: 0.0000e+00 - val_loss: 0.0210 - val_acc: 0.0500\n",
      "Epoch 376/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0160 - acc: 0.0000e+00 - val_loss: 0.0211 - val_acc: 0.0500\n",
      "Epoch 377/500\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.0159 - acc: 0.0000e+00 - val_loss: 0.0213 - val_acc: 0.0500\n",
      "Epoch 378/500\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.0158 - acc: 0.0000e+00 - val_loss: 0.0216 - val_acc: 0.0500\n",
      "Epoch 379/500\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.0158 - acc: 0.0000e+00 - val_loss: 0.0216 - val_acc: 0.0500\n",
      "Epoch 380/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.0158 - acc: 0.0000e+00 - val_loss: 0.0214 - val_acc: 0.0500\n",
      "Epoch 381/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0158 - acc: 0.0000e+00 - val_loss: 0.0213 - val_acc: 0.0500\n",
      "Epoch 382/500\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.0157 - acc: 0.0000e+00 - val_loss: 0.0211 - val_acc: 0.0500\n",
      "Epoch 383/500\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.0157 - acc: 0.0000e+00 - val_loss: 0.0208 - val_acc: 0.0500\n",
      "Epoch 384/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.0158 - acc: 0.0000e+00 - val_loss: 0.0208 - val_acc: 0.0500\n",
      "Epoch 385/500\n",
      "80/80 [==============================] - 0s 225us/step - loss: 0.0157 - acc: 0.0000e+00 - val_loss: 0.0211 - val_acc: 0.0500\n",
      "Epoch 386/500\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.0156 - acc: 0.0000e+00 - val_loss: 0.0213 - val_acc: 0.0500\n",
      "Epoch 387/500\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.0157 - acc: 0.0000e+00 - val_loss: 0.0214 - val_acc: 0.0500\n",
      "Epoch 388/500\n",
      "80/80 [==============================] - 0s 263us/step - loss: 0.0156 - acc: 0.0000e+00 - val_loss: 0.0212 - val_acc: 0.0500\n",
      "Epoch 389/500\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.0156 - acc: 0.0000e+00 - val_loss: 0.0208 - val_acc: 0.0500\n",
      "Epoch 390/500\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.0156 - acc: 0.0000e+00 - val_loss: 0.0208 - val_acc: 0.0500\n",
      "Epoch 391/500\n",
      "80/80 [==============================] - 0s 263us/step - loss: 0.0156 - acc: 0.0000e+00 - val_loss: 0.0209 - val_acc: 0.0500\n",
      "Epoch 392/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0155 - acc: 0.0000e+00 - val_loss: 0.0208 - val_acc: 0.0500\n",
      "Epoch 393/500\n",
      "80/80 [==============================] - 0s 163us/step - loss: 0.0155 - acc: 0.0000e+00 - val_loss: 0.0207 - val_acc: 0.0500\n",
      "Epoch 394/500\n",
      "80/80 [==============================] - 0s 288us/step - loss: 0.0155 - acc: 0.0000e+00 - val_loss: 0.0208 - val_acc: 0.0500\n",
      "Epoch 395/500\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.0155 - acc: 0.0000e+00 - val_loss: 0.0208 - val_acc: 0.0500\n",
      "Epoch 396/500\n",
      "80/80 [==============================] - 0s 263us/step - loss: 0.0155 - acc: 0.0000e+00 - val_loss: 0.0209 - val_acc: 0.0500\n",
      "Epoch 397/500\n",
      "80/80 [==============================] - 0s 225us/step - loss: 0.0154 - acc: 0.0000e+00 - val_loss: 0.0208 - val_acc: 0.0500\n",
      "Epoch 398/500\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.0154 - acc: 0.0000e+00 - val_loss: 0.0206 - val_acc: 0.0500\n",
      "Epoch 399/500\n",
      "80/80 [==============================] - 0s 263us/step - loss: 0.0154 - acc: 0.0000e+00 - val_loss: 0.0206 - val_acc: 0.0500\n",
      "Epoch 400/500\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.0154 - acc: 0.0000e+00 - val_loss: 0.0205 - val_acc: 0.0500\n",
      "Epoch 401/500\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.0154 - acc: 0.0000e+00 - val_loss: 0.0205 - val_acc: 0.0500\n",
      "Epoch 402/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.0154 - acc: 0.0000e+00 - val_loss: 0.0205 - val_acc: 0.0500\n",
      "Epoch 403/500\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.0154 - acc: 0.0000e+00 - val_loss: 0.0202 - val_acc: 0.0500\n",
      "Epoch 404/500\n",
      "80/80 [==============================] - 0s 225us/step - loss: 0.0154 - acc: 0.0000e+00 - val_loss: 0.0202 - val_acc: 0.0500\n",
      "Epoch 405/500\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.0154 - acc: 0.0000e+00 - val_loss: 0.0203 - val_acc: 0.0500\n",
      "Epoch 406/500\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.0153 - acc: 0.0000e+00 - val_loss: 0.0204 - val_acc: 0.0500\n",
      "Epoch 407/500\n",
      "80/80 [==============================] - 0s 225us/step - loss: 0.0153 - acc: 0.0000e+00 - val_loss: 0.0204 - val_acc: 0.0500\n",
      "Epoch 408/500\n",
      "80/80 [==============================] - 0s 163us/step - loss: 0.0153 - acc: 0.0000e+00 - val_loss: 0.0204 - val_acc: 0.0500\n",
      "Epoch 409/500\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.0152 - acc: 0.0000e+00 - val_loss: 0.0204 - val_acc: 0.0500\n",
      "Epoch 410/500\n",
      "80/80 [==============================] - 0s 225us/step - loss: 0.0152 - acc: 0.0000e+00 - val_loss: 0.0205 - val_acc: 0.0500\n",
      "Epoch 411/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 250us/step - loss: 0.0152 - acc: 0.0000e+00 - val_loss: 0.0204 - val_acc: 0.0500\n",
      "Epoch 412/500\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.0152 - acc: 0.0000e+00 - val_loss: 0.0203 - val_acc: 0.0500\n",
      "Epoch 413/500\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0139 - acc: 0.0000e+0 - 0s 188us/step - loss: 0.0152 - acc: 0.0000e+00 - val_loss: 0.0202 - val_acc: 0.0500\n",
      "Epoch 414/500\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.0152 - acc: 0.0000e+00 - val_loss: 0.0201 - val_acc: 0.0500\n",
      "Epoch 415/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.0152 - acc: 0.0000e+00 - val_loss: 0.0199 - val_acc: 0.0500\n",
      "Epoch 416/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.0151 - acc: 0.0000e+00 - val_loss: 0.0202 - val_acc: 0.0500\n",
      "Epoch 417/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0151 - acc: 0.0000e+00 - val_loss: 0.0203 - val_acc: 0.0500\n",
      "Epoch 418/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.0152 - acc: 0.0000e+00 - val_loss: 0.0204 - val_acc: 0.0500\n",
      "Epoch 419/500\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.0152 - acc: 0.0000e+00 - val_loss: 0.0202 - val_acc: 0.0500\n",
      "Epoch 420/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.0151 - acc: 0.0000e+00 - val_loss: 0.0200 - val_acc: 0.0500\n",
      "Epoch 421/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0151 - acc: 0.0000e+00 - val_loss: 0.0198 - val_acc: 0.0500\n",
      "Epoch 422/500\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.0151 - acc: 0.0000e+00 - val_loss: 0.0197 - val_acc: 0.0500\n",
      "Epoch 423/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0151 - acc: 0.0000e+00 - val_loss: 0.0199 - val_acc: 0.0500\n",
      "Epoch 424/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0151 - acc: 0.0000e+00 - val_loss: 0.0200 - val_acc: 0.0500\n",
      "Epoch 425/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0151 - acc: 0.0000e+00 - val_loss: 0.0198 - val_acc: 0.0500\n",
      "Epoch 426/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.0151 - acc: 0.0000e+00 - val_loss: 0.0197 - val_acc: 0.0500\n",
      "Epoch 427/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.0150 - acc: 0.0000e+00 - val_loss: 0.0198 - val_acc: 0.0500\n",
      "Epoch 428/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0150 - acc: 0.0000e+00 - val_loss: 0.0197 - val_acc: 0.0500\n",
      "Epoch 429/500\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.0150 - acc: 0.0000e+00 - val_loss: 0.0196 - val_acc: 0.0500\n",
      "Epoch 430/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0150 - acc: 0.0000e+00 - val_loss: 0.0196 - val_acc: 0.0500\n",
      "Epoch 431/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0150 - acc: 0.0000e+00 - val_loss: 0.0196 - val_acc: 0.0500\n",
      "Epoch 432/500\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.0150 - acc: 0.0000e+00 - val_loss: 0.0196 - val_acc: 0.0500\n",
      "Epoch 433/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0150 - acc: 0.0000e+00 - val_loss: 0.0197 - val_acc: 0.0500\n",
      "Epoch 434/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.0150 - acc: 0.0000e+00 - val_loss: 0.0197 - val_acc: 0.0500\n",
      "Epoch 435/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.0150 - acc: 0.0000e+00 - val_loss: 0.0197 - val_acc: 0.0500\n",
      "Epoch 436/500\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.0150 - acc: 0.0000e+00 - val_loss: 0.0195 - val_acc: 0.0500\n",
      "Epoch 437/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0150 - acc: 0.0000e+00 - val_loss: 0.0194 - val_acc: 0.0500\n",
      "Epoch 438/500\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.0150 - acc: 0.0000e+00 - val_loss: 0.0194 - val_acc: 0.0500\n",
      "Epoch 439/500\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.0149 - acc: 0.0000e+00 - val_loss: 0.0196 - val_acc: 0.0500\n",
      "Epoch 440/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0149 - acc: 0.0000e+00 - val_loss: 0.0198 - val_acc: 0.0500\n",
      "Epoch 441/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.0149 - acc: 0.0000e+00 - val_loss: 0.0198 - val_acc: 0.0500\n",
      "Epoch 442/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.0150 - acc: 0.0000e+00 - val_loss: 0.0197 - val_acc: 0.0500\n",
      "Epoch 443/500\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.0150 - acc: 0.0000e+00 - val_loss: 0.0193 - val_acc: 0.0500\n",
      "Epoch 444/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0150 - acc: 0.0000e+00 - val_loss: 0.0191 - val_acc: 0.0500\n",
      "Epoch 445/500\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.0150 - acc: 0.0000e+00 - val_loss: 0.0192 - val_acc: 0.0500\n",
      "Epoch 446/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0149 - acc: 0.0000e+00 - val_loss: 0.0193 - val_acc: 0.0500\n",
      "Epoch 447/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0149 - acc: 0.0000e+00 - val_loss: 0.0197 - val_acc: 0.0500\n",
      "Epoch 448/500\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.0149 - acc: 0.0000e+00 - val_loss: 0.0197 - val_acc: 0.0500\n",
      "Epoch 449/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.0149 - acc: 0.0000e+00 - val_loss: 0.0197 - val_acc: 0.0500\n",
      "Epoch 450/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0149 - acc: 0.0000e+00 - val_loss: 0.0196 - val_acc: 0.0500\n",
      "Epoch 451/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0149 - acc: 0.0000e+00 - val_loss: 0.0194 - val_acc: 0.0500\n",
      "Epoch 452/500\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.0149 - acc: 0.0000e+00 - val_loss: 0.0195 - val_acc: 0.0500\n",
      "Epoch 453/500\n",
      "80/80 [==============================] - 0s 163us/step - loss: 0.0149 - acc: 0.0000e+00 - val_loss: 0.0193 - val_acc: 0.0500\n",
      "Epoch 454/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.0149 - acc: 0.0000e+00 - val_loss: 0.0193 - val_acc: 0.0500\n",
      "Epoch 455/500\n",
      "80/80 [==============================] - 0s 163us/step - loss: 0.0148 - acc: 0.0000e+00 - val_loss: 0.0194 - val_acc: 0.0500\n",
      "Epoch 456/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.0149 - acc: 0.0000e+00 - val_loss: 0.0194 - val_acc: 0.0500\n",
      "Epoch 457/500\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.0148 - acc: 0.0000e+00 - val_loss: 0.0194 - val_acc: 0.0500\n",
      "Epoch 458/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0148 - acc: 0.0000e+00 - val_loss: 0.0194 - val_acc: 0.0500\n",
      "Epoch 459/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.0148 - acc: 0.0000e+00 - val_loss: 0.0192 - val_acc: 0.0500\n",
      "Epoch 460/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.0149 - acc: 0.0000e+00 - val_loss: 0.0190 - val_acc: 0.0500\n",
      "Epoch 461/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0148 - acc: 0.0000e+00 - val_loss: 0.0190 - val_acc: 0.0500\n",
      "Epoch 462/500\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.0148 - acc: 0.0000e+00 - val_loss: 0.0189 - val_acc: 0.0500\n",
      "Epoch 463/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0148 - acc: 0.0000e+00 - val_loss: 0.0190 - val_acc: 0.0500\n",
      "Epoch 464/500\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.0148 - acc: 0.0000e+00 - val_loss: 0.0194 - val_acc: 0.0500\n",
      "Epoch 465/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.0149 - acc: 0.0000e+00 - val_loss: 0.0195 - val_acc: 0.0500\n",
      "Epoch 466/500\n",
      "80/80 [==============================] - 0s 163us/step - loss: 0.0148 - acc: 0.0000e+00 - val_loss: 0.0192 - val_acc: 0.0500\n",
      "Epoch 467/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0148 - acc: 0.0000e+00 - val_loss: 0.0190 - val_acc: 0.0500\n",
      "Epoch 468/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0148 - acc: 0.0000e+00 - val_loss: 0.0189 - val_acc: 0.0500\n",
      "Epoch 469/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0148 - acc: 0.0000e+00 - val_loss: 0.0189 - val_acc: 0.0500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 470/500\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.0148 - acc: 0.0000e+00 - val_loss: 0.0191 - val_acc: 0.0500\n",
      "Epoch 471/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.0148 - acc: 0.0000e+00 - val_loss: 0.0191 - val_acc: 0.0500\n",
      "Epoch 472/500\n",
      "80/80 [==============================] - 0s 163us/step - loss: 0.0148 - acc: 0.0000e+00 - val_loss: 0.0191 - val_acc: 0.0500\n",
      "Epoch 473/500\n",
      "80/80 [==============================] - 0s 150us/step - loss: 0.0148 - acc: 0.0000e+00 - val_loss: 0.0190 - val_acc: 0.0500\n",
      "Epoch 474/500\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.0148 - acc: 0.0000e+00 - val_loss: 0.0190 - val_acc: 0.0500\n",
      "Epoch 475/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0147 - acc: 0.0000e+00 - val_loss: 0.0191 - val_acc: 0.0500\n",
      "Epoch 476/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0148 - acc: 0.0000e+00 - val_loss: 0.0190 - val_acc: 0.0500\n",
      "Epoch 477/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0148 - acc: 0.0000e+00 - val_loss: 0.0187 - val_acc: 0.0500\n",
      "Epoch 478/500\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.0147 - acc: 0.0000e+00 - val_loss: 0.0187 - val_acc: 0.0500\n",
      "Epoch 479/500\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.0147 - acc: 0.0000e+00 - val_loss: 0.0188 - val_acc: 0.0500\n",
      "Epoch 480/500\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.0147 - acc: 0.0000e+00 - val_loss: 0.0190 - val_acc: 0.0500\n",
      "Epoch 481/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.0148 - acc: 0.0000e+00 - val_loss: 0.0191 - val_acc: 0.0500\n",
      "Epoch 482/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.0148 - acc: 0.0000e+00 - val_loss: 0.0190 - val_acc: 0.0500\n",
      "Epoch 483/500\n",
      "80/80 [==============================] - 0s 163us/step - loss: 0.0147 - acc: 0.0000e+00 - val_loss: 0.0187 - val_acc: 0.0500\n",
      "Epoch 484/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.0148 - acc: 0.0000e+00 - val_loss: 0.0183 - val_acc: 0.0500\n",
      "Epoch 485/500\n",
      "80/80 [==============================] - 0s 163us/step - loss: 0.0148 - acc: 0.0000e+00 - val_loss: 0.0183 - val_acc: 0.0500\n",
      "Epoch 486/500\n",
      "80/80 [==============================] - 0s 163us/step - loss: 0.0148 - acc: 0.0000e+00 - val_loss: 0.0184 - val_acc: 0.0500\n",
      "Epoch 487/500\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.0148 - acc: 0.0000e+00 - val_loss: 0.0190 - val_acc: 0.0500\n",
      "Epoch 488/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.0147 - acc: 0.0000e+00 - val_loss: 0.0191 - val_acc: 0.0500\n",
      "Epoch 489/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.0147 - acc: 0.0000e+00 - val_loss: 0.0190 - val_acc: 0.0500\n",
      "Epoch 490/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.0147 - acc: 0.0000e+00 - val_loss: 0.0187 - val_acc: 0.0500\n",
      "Epoch 491/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.0147 - acc: 0.0000e+00 - val_loss: 0.0185 - val_acc: 0.0500\n",
      "Epoch 492/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.0147 - acc: 0.0000e+00 - val_loss: 0.0184 - val_acc: 0.0500\n",
      "Epoch 493/500\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.0147 - acc: 0.0000e+00 - val_loss: 0.0186 - val_acc: 0.0500\n",
      "Epoch 494/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.0147 - acc: 0.0000e+00 - val_loss: 0.0187 - val_acc: 0.0500\n",
      "Epoch 495/500\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0147 - acc: 0.0000e+00 - val_loss: 0.0188 - val_acc: 0.0500\n",
      "Epoch 496/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.0147 - acc: 0.0000e+00 - val_loss: 0.0189 - val_acc: 0.0500\n",
      "Epoch 497/500\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.0147 - acc: 0.0000e+00 - val_loss: 0.0189 - val_acc: 0.0500\n",
      "Epoch 498/500\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.0147 - acc: 0.0000e+00 - val_loss: 0.0186 - val_acc: 0.0500\n",
      "Epoch 499/500\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.0147 - acc: 0.0000e+00 - val_loss: 0.0185 - val_acc: 0.0500\n",
      "Epoch 500/500\n",
      "80/80 [==============================] - 0s 225us/step - loss: 0.0146 - acc: 0.0000e+00 - val_loss: 0.0185 - val_acc: 0.0500\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train,y_train,epochs=500,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(range(20),results,c='r')\n",
    "plt.scatter(range(20),y_test,c='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAH2NJREFUeJzt3Xl0XOWZ5/HvU6UNS/KqkhfJK5aNZWxsLIwJhhhsCFtsYkgCCd3JDD3MzAkNfdJJB4ZuJqHTWbs7yaRJOgwhyXQnEMIWQ5wYMHbCDvKCQV6wvGALL5KN90VbPfNHle1Cka2yXKpbVfp9ztGpuu99q/S8svyrq7u819wdERHJLaGgCxARkdRTuIuI5CCFu4hIDlK4i4jkIIW7iEgOUriLiOQghbuISA5SuIuI5CCFu4hIDsoL6huXlZX5qFGjgvr2IiJZadmyZbvcPdJVv8DCfdSoUdTW1gb17UVEspKZvZdMP+2WERHJQQp3EZEcpHAXEclBCncRkRykcBcRyUEKdxGRHKRwFxHJQVkX7mu27+fbf1iLbg8oInJyWRfur23czY+XbmDxmsagSxERyVhZF+63zBjJmEgx31i4hpa2aNDliIhkpKwL9/xwiHuumcDGXYf4z9eSugpXRKTXybpwB7j8nHJmji3jB4vXs/dwS9DliIhknKwMdzPj76+bwIGjrXz/+fVBlyMiknGyMtwBzhnSl09fMIL/fO09NjQdDLocEZGMkrXhDvDFK8ZRlB/mG79bE3QpIiIZJavDPVJayBcuG8vitY386d2moMsREckYSYW7mV1lZuvMrN7M7jpJn0+Z2WozqzOzX6W2zJP7LxePYtSgPnx1QR3Nbe3p+rYiIhmty3A3szBwP3A1UA3cbGbVHfpUAXcDF7v7ROBveqDWThXlh/nq3Ils3HWIB1/clK5vKyKS0ZLZcp8O1Lv7RndvAR4B5nXo89+A+919D4C7p/Xy0Vnjy7lq4hB++MJ6GvYcTue3FhHJSMmEewWwNWG5Id6WaBwwzsxeNrPXzOyqzt7IzG4zs1ozq21qSu0+8ns/Xo1h3Pf06pS+r4hINkom3K2Tto6zduUBVcAs4GbgQTPr/2cvcn/A3WvcvSYS6fLm3adlWP+zuGN2Fc+u3smStZp3RkR6t2TCvQEYnrBcCWzrpM9v3b3V3TcB64iFfVrdOnM0Z0eK+d8L6jjaqoOrItJ7JRPubwJVZjbazAqAm4AFHfo8BVwGYGZlxHbTbExlockoyAvx9esnseWDw/xgsa5cFZHeq8twd/c24HZgEbAGeNTd68zsPjObG++2CNhtZquBJcCX3X13TxV9KhedPYhP1VTywJ82smb7/iBKEBEJnAV104uamhqvra3tkffee7iF2f/yRyoH9uGJ//kRwqHODhuIiGQfM1vm7jVd9cvqK1RPpn+fAu79eDVvbd3Lf7y6OehyRETSLifDHWDuecP46LgI3120jvf3Hgm6HBGRtMrZcDczvn79uThwz5Nv656rItKr5Gy4Awwf2Ie/+9h4lq5r4skV7wddjohI2uR0uAP85UWjmDZyAPc9s5qmA81BlyMikhY5H+6hkPHtGyZzuLmdrz5dF3Q5IiJpkfPhDjC2vIQ751Txu1XbWVS3I+hyRER6XK8Id4DbLh3DhKF9+Yen3mHfkdagyxER6VG9JtzzwyG+e+Nkdh9q0W35RCTn9ZpwBzi3oh+3XTqGX9du5eX6XUGXIyLSY3pVuAPcObuKMWXF3PXEKg63tAVdjohIj+h14V6UH+ZbN0xm6wdH+OdF7wZdjohIj+h14Q4wffRA/mLGSH72yiaWb9kTdDkiIinXK8Md4CtXn8PQvkV85bFVNLfpxh4iklt6bbiXFObxT/Mnsb7xIPcv2RB0OSIiKdVrwx3gsvHlzJ9awY+W1OvGHiKSU3p1uAP8w3XV9O+Tz11PvE00qpkjRSQ39PpwH1BcwD3XTuCtrXt5bHlD0OWIiKRErw93gOunVDBt5AC+84e17D+qqQlEJPsp3Ind2ONrcyey+1AL339ufdDliIicMYV73LkV/bjpghH84tXNrN95IOhyRETOiMI9wZc/Np6Swjy+9vRq3ZZPRLKawj3BwOIC7pxdxUv1u/jTek0sJiLZK6lwN7OrzGydmdWb2V2drP+8mTWZ2cr411+lvtT0+OyMEQwfeBbf+v1anRopIlmry3A3szBwP3A1UA3cbGbVnXT9tbtPiX89mOI606YwL8yXrhzPmu37eWqlbqotItkpmS336UC9u2909xbgEWBez5YVrI9PHsakin78y7PvcrRV886ISPZJJtwrgK0Jyw3xto5uMLNVZvaYmQ3v7I3M7DYzqzWz2qampm6Umx6hkHHX1efw/t4jPPzGlqDLERE5bcmEu3XS1nFn9NPAKHefDDwP/KKzN3L3B9y9xt1rIpHI6VWaZhePLWP66IH8+x83aOtdRLJOMuHeACRuiVcC2xI7uPtud2+OL/5fYFpqygvWnbOr2Lm/md8s07QEIpJdkgn3N4EqMxttZgXATcCCxA5mNjRhcS6QE3eg/sjZg5g2cgA/XlKvOd9FJKt0Ge7u3gbcDiwiFtqPunudmd1nZnPj3e4wszozewu4A/h8TxWcTmbGHbOr2LbvKI8v05kzIpI9LKgrMWtqary2tjaQ73063J1P/OgVmg40s/TLs8gP67ovEQmOmS1z95qu+impumBm3Dm7ivf3HuG3K7d1/QIRkQygcE/CrPERxg0u4cEXN2rOGRHJCgr3JJgZt84czdodB3h1w+6gyxER6ZLCPUnzplQwqLiAn760KehSRES6pHBPUlF+mFtmjGTx2kY2Nh0MuhwRkVNSuJ+GW2aMpCAvxEMva+tdRDKbwv00REoLmXveMJ5c/j4Hm9uCLkdE5KQU7qfplhkjOdTSzlMrdFGTiGQuhftpOq+yH9VD+/LL17fotEgRyVgK99NkZnx2xgjWbN/Piq17gy5HRKRTCvdumDelguKCML98TXO9i0hmUrh3Q0lhHtdPreCZVdvYd7g16HJERP6Mwr2bbp4+gua2KAtWab4ZEck8CvdumjisL+cMKeWJ5bqRh4hkHoV7N5kZ88+vYMWWvWzQFasikmEU7mfg+ikVhAyeXK5z3kUksyjcz0B53yIuqYrw5Ir3iUZ1zruIZA6F+xm6YVol7+89wmubNBWwiGQOhfsZurJ6MKWFebrHqohkFIX7GSrKD3Pt5KH8/p3tHG7RZGIikhkU7ikw//xKDre089zqnUGXIiICKNxTombkAAb3LWTh29uDLkVEBEgy3M3sKjNbZ2b1ZnbXKfrdaGZuZjWpKzHzhULG1ecOZcm6Js3zLiIZoctwN7MwcD9wNVAN3Gxm1Z30KwXuAF5PdZHZ4NrJQ2lpi7J4jXbNiEjwktlynw7Uu/tGd28BHgHmddLvH4HvAEdTWF/WmDZCu2ZEJHMkE+4VwNaE5YZ423FmNhUY7u7PpLC2rKJdMyKSSZIJd+uk7fjlmGYWAr4H/G2Xb2R2m5nVmlltU1NT8lVmiWsmadeMiGSGZMK9ARiesFwJJM5zWwqcCyw1s83ADGBBZwdV3f0Bd69x95pIJNL9qjNUzcgBlJdq14yIBC+ZcH8TqDKz0WZWANwELDi20t33uXuZu49y91HAa8Bcd6/tkYozWChkXDNpKEu1a0ZEAtZluLt7G3A7sAhYAzzq7nVmdp+Zze3pArPNNZOG0qxdMyISsLxkOrn7QmBhh7Z7T9J31pmXlb0Sd83Mm1LR9QtERHqArlBNsdhZM0NYuq6JIy3tQZcjIr2Uwr0HXFE9hOa2KC+uz70zgkQkOyjce8CFYwZSWpSnicREJDAK9x6QHw5x2fhyXljbSLvu0CQiAVC495A51YPZfaiFFVv2BF2KiPRCCvceMmt8hPywadeMiARC4d5D+hblM2PMIIW7iARC4d6D5kwYzMZdh6hvPBh0KSLSyyjce9Cc6sEAPK+rVUUkzRTuPaii/1lMHNZXu2ZEJO0U7j1szoTBLN+yhw8OtQRdioj0Igr3HjZrfAR3dLWqiKSVwr2HTa7sz4A++fxxncJdRNJH4d7DwiHjkqoIf3y3iaiuVhWRNFG4p8Gs8RF2H2rhnW37gi5FRHoJhXsaXDoudktB7ZoRkXRRuKdBWUkhkyv7sfRdhbuIpIfCPU0+Oi7Cii172HtYp0SKSM9TuKfJrPERog4v1e8KuhQR6QUU7mkyZfgA+p2Vz1LtdxeRNFC4p0nslMgynRIpImmhcE+jWePLaTrQzOrt+4MuRURynMI9jS4dVwbAH3XWjIj0sKTC3cyuMrN1ZlZvZnd1sv5/mNnbZrbSzF4ys+rUl5r9ykuLmDisr853F5Ee12W4m1kYuB+4GqgGbu4kvH/l7pPcfQrwHeBfU15pjpg1PsKyLXvYd6Q16FJEJIcls+U+Hah3943u3gI8AsxL7ODuiTuRiwEdMTyJj44rpz3qvLpBp0SKSM9JJtwrgK0Jyw3xtg8xsy+Y2QZiW+53pKa83DN1RH+KC8I6311EelQy4W6dtP3Zlrm73+/uZwNfAf6+0zcyu83Mas2stqmpd+53zg+HuHDMIF6u3x10KSKSw5IJ9wZgeMJyJbDtFP0fAa7vbIW7P+DuNe5eE4lEkq8yx8wcW8amXYdo2HM46FJEJEclE+5vAlVmNtrMCoCbgAWJHcysKmHxWmB96krMPTOrYqdEvqKtdxHpIV2Gu7u3AbcDi4A1wKPuXmdm95nZ3Hi3282szsxWAl8EPtdjFeeAqvISIqWFvKj97iLSQ/KS6eTuC4GFHdruTXh+Z4rrymlmxsyxZfwpPhVBKNTZYQ0Rke7TFaoBmTm2jN2HWli740DQpYhIDlK4B+TisbH97i/V986zhkSkZyncAzKkXxFjy0t4SQdVRaQHKNwDNHNsGW9s2k1zW3vQpYhIjlG4B2jm2DKOtkZZ/t7eoEsRkRyjcA/QhWMGEg6Z9ruLSMop3ANUWpTPlOH9td9dRFJO4R6wi8eW8XbDXvYd1hTAIpI6CveAXVJVRtTh1Y26WlVEUkfhHrApwzUFsIiknsI9YJoCWER6gsI9A1ysKYBFJMUU7hngkvgUwC9r14yIpIjCPQMcmwJYp0SKSKoo3DPAsSmAX6nfRTSqe4uLyJlTuGeIi+NTAK/ZsT/oUkQkByjcM8TMsdrvLiKpo3DPEJoCWERSSeGeQWaOLeP1jbs50qIpgEXkzCjcM8jl55TT3BbllQ3aNSMiZ0bhnkEuHDOQ4oIwz69pDLoUEclyCvcMUpgX5pKqCC+s3Ym7TokUke5TuGeY2RPK2bm/mbptOiVSRLovqXA3s6vMbJ2Z1ZvZXZ2s/6KZrTazVWa22MxGpr7U3uGyc8oxg+fX7Ay6FBHJYl2Gu5mFgfuBq4Fq4GYzq+7QbQVQ4+6TgceA76S60N6irKSQqcP7s1j73UXkDCSz5T4dqHf3je7eAjwCzEvs4O5L3P3YlIavAZWpLbN3mT1hMG+/v4+d+48GXYqIZKlkwr0C2Jqw3BBvO5lbgd+fSVG93ZwJgwF4brV2zYhI9yQT7tZJW6encpjZLUAN8N2TrL/NzGrNrLapqSn5KnuZcYNLGFNWzMK3twddiohkqWTCvQEYnrBcCWzr2MnM5gD3AHPdvbmzN3L3B9y9xt1rIpFId+rtFcyM6yYP5bWNu2k60OmPUkTklJIJ9zeBKjMbbWYFwE3AgsQOZjYV+AmxYNeRwBS4dvIwog5/eEdb7yJy+roMd3dvA24HFgFrgEfdvc7M7jOzufFu3wVKgN+Y2UozW3CSt5MkjR9SSlV5Cc+sUriLyOnLS6aTuy8EFnZouzfh+ZwU1yXAtZOH8oPF62ncf5TyvkVBlyMiWURXqGaw6yYPxR0dWBWR06Zwz2Bjy0s5Z0gpT2vXjIicJoV7hps3pYJl7+1h865DQZciIllE4Z7h5p9fQcjgsWUNQZciIllE4Z7hBvct4tJxER5f3kBbezTockQkSyjcs8Bnpo9g+76jOi1SRJKmcM8CcyYM5pwhpfzwhfW0R3UTDxHpmsI9C4RCxl9fXsWGpkM6LVJEkqJwzxJXnzuEqvISfvjCeqLaeheRLijcs0QoZPz17Cre3XmQ37+zI+hyRCTDKdyzyLWThjJucAnf/sNamtvagy5HRDKYwj2LhEPGP1xXzZYPDvOzlzcHXY6IZDCFe5a5pCrCnAnl/NsL9TTqNnwichIK9yx0z7XVtEWj3P7wClp1YZOIdELhnoVGlxXzrfmTeWPTB3xz4dqgyxGRDJTUfO6Sea6fWsFbDXt56OVNnDe8H/OmnOqe5SLS22jLPYv9r2smMH3UQL7y+CpWbt0bdDkikkEU7lksPxzi/s+eT6S0kFsefJ1XN+wOuiQRyRAK9ywXKS3k0f9+EYP7FnLLT1/nwRc34q4rWEV6O4V7Dhja7yye+sLFzJlQztd/t4ZP/+Q13m7YF3RZIhIghXuOKC3K599vmcY3PjGJDU0H+fi/vcQXH13Jjn06F16kN7Kg/oSvqanx2traQL53rtt/tJUfLdnAQy9tAoP5Uyv4rzNHM25wadClicgZMrNl7l7TZT+Fe+7a+sFhfrR0A08sb6C5LcolVWXcOnM0Hx0XwcyCLk9EuiHZcE9qt4yZXWVm68ys3szu6mT9pWa23MzazOzG7hQsqTd8YB++OX8Sr949my9dOY51Ow7w+Z+9yRXf+xO/en0LR1s1+ZhIrupyy93MwsC7wBVAA/AmcLO7r07oMwroC3wJWODuj3X1jbXlnn4tbVGeWbWNn760ibpt++lblMf88yu5afpwzhnSN+jyRCQJyW65J3OF6nSg3t03xt/4EWAecDzc3X1zfJ0mOslgBXkh5p9fySemVvD6pg/45etb+NXrW/j5K5uZMrw/N08fznWTh1FcqAuXRbJdMv+LK4CtCcsNwIU9U46kg5kxY8wgZowZxAeHWnhieQOPvLmVrzz+Nv/4zBo+ft4wPjN9BJMq+wVdqoh0UzLh3tmRt24dhTWz24DbAEaMGNGdt5AUG1hcwF9dMoZbZ45m2Xt7ePiNrTy5ooGH39jCxGF9uemC4cw9r4J+ffKDLlVETkMy+9wvAr7q7h+LL98N4O7f7KTvz4FntM89u+070sqCle/z8BtbWb19PwV5IT42cQifnFbJxWPLCId0po1IUFK5z/1NoMrMRgPvAzcBnznD+iSD9Tsrn7+4aBS3zBhJ3bb9/KZ2K0+t3MbTb21jaL8ibji/khunVTKqrDjoUkXkJJI6z93MrgG+D4SBh9z9n8zsPqDW3ReY2QXAk8AA4Ciww90nnuo9teWeXZrb2nl+dSOP1m7lxfVNRB2mjx7IJ6dVcs2koToIK5ImuohJesyOfUd5fHkDjy1rYNOuQxQXhLlu8jA+dUEl548YoAukRHqQwl16nLuz7L09PFq7lWdWbedwSztjy0v4VE0ln5haSaS0MOgSRXKOwl3S6mBzG79btY1HaxtY9t4e8kLG5eeU8+kLhvPRcRHywpqjTiQVFO4SmPrGAzxa28ATyxvYdbCF8tJCbphWyadqhjNaB2FFzojCXQLX2h7lhbWNPPrmVpasazx+EPbGaZVcfe4QSot07rzI6VK4S0bZuT92EPY3tbGDsEX5Ia6oHsL8qRVcUlWm3TYiSVK4S0Zyd5Zv2cuTKxp4ZtV29h5upaykgOsmD2P++RVMquins21ETkHhLhmvpS3K0nWNPLnifRavaaSlPcrZkWLmn1/JvCnDqBzQJ+gSRTKOwl2yyr7Drfzu7e08uaKBNzfvAWDK8P5cOXEwV1YPYWx5ScAVimQGhbtkra0fHGbBW9tYVLeDVfEbfY+JFHNFdSzopw7vT0jz20gvpXCXnLBt7xGeX7OT51bv5NUNu2mLOpHSQuZMGMyVEwfzkbMHUZgXDrpMkbRRuEvO2XeklaXrGnm2bidL1zVyqKWd4oIws8aXc+XEwcwaX06/s3R6peQ2hbvktOa2dl7ZsJtn62Jb9bsONpMXMi46exBXVA/miurBDO13VtBliqScwl16jWjUWbF1L8+t3smzdTvYuOsQAJMr+3Fl9WCunDiEqvISnWIpOUHhLr1WfeNBnl29g2frdrJy614ARg7qw5XVg/nYxCFMHTFANxyRrKVwFyF2Zexzq2O7bl7ZsIvWdqespCDhgGwZRfk6ICvZQ+Eu0sGBo60sXdfEs6t3smRtIweb2z50QPayc8rpq/luJMMp3EVOobmtndc2fsCiuh08t3onTQeayQ8b548YwPTRA7lg1EDOq+yvG4NLxlG4iyTp2AHZZ1fv4JX63dRt20c0/t9iUHEBYyLFjCkrYUykmNFlxQzpV0R5aRFlJQWa8EzSLpU3yBbJaaGQMW3kAKaNHADEbjyy/L09rNm+n41Nh9i46yCL1+7k17UtH3qdGQwqLqS8tJDyvvHH0qLjzyOlhfQtyqekKI+SwjyKC/J0Za2kjcJdpIOSwjwuHRfh0nGRD7XvO9zK5t2H2Ln/KI0Hmmk80EzTgaM07o89X71tP7sONh/f6u/IDEoK8o6H/bHHvkX5H1ouTVhfGl9XmvABUZgfoiAc0geFnJLCXSRJ/frkc16f/qfs0x51dh9qpnF/M00Hmzl4tI2DzW0cPNrGgeY2DhxtPdHW3MaBo21s33f0ePuhlvak6ykIhyjMC1GYH6IoP8xZ+WHOKghTEA6RHw6RnxeiIGzkh0MU5MXbwifa8uNthXkh8sNGOHTs0QibEQoZeaHYcsji7fF14dCJ9SfWQciMvFCIUIgPvU/IjJDF1ttJHkNmGPG2EMdfYyT2OfEaXbdwagp3kRQKhyy2a6a0qFuvb486h1rajn8AHDjayoGED4iDzW20tEdpbo0efzzS2k5zaztH4l+t7VFa25zDR1ppbYvGltujtLY7Lceet0Xjz4M55pYqoYQPBuzDy/EmLOE5nPhQOLF8YunY50XiOktYZ4mvt8T+1slr7fhzEtaZGXfMrmLuecNS9FPonMJdJIOEQ0bfovy0nZLp7sdDv73daYtGaYs67Ylf7kTjj4ntUXfao9AWjRKNcrxf24fWxx6j7rhD1Ik/d6JOvO3E8ol+Jx6jDk58OZrQL15/NOG1JLzm2Ht4vG9svPHHeEv8JR9aR+K6hP7H+nq8HvxE72MnpiS+14nnCevijf3TMAdSUuFuZlcBPwDCwIPu/q0O6wuB/wdMA3YDn3b3zaktVURSzcwoyDMK8nTWT67p8l/UzMLA/cDVQDVws5lVd+h2K7DH3ccC3wO+nepCRUQkecl8XE8H6t19o7u3AI8A8zr0mQf8Iv78MWC26WiHiEhgkgn3CmBrwnJDvK3TPu7eBuwDBqWiQBEROX3JhHtnW+AdD7En0wczu83Mas2stqmpKZn6RESkG5IJ9wZgeMJyJbDtZH3MLA/oB3zQ8Y3c/QF3r3H3mkgk0nG1iIikSDLh/iZQZWajzawAuAlY0KHPAuBz8ec3Ai94UJPWiIhI16dCunubmd0OLCJ2KuRD7l5nZvcBte6+APgp8B9mVk9si/2mnixaREROLanz3N19IbCwQ9u9Cc+PAp9MbWkiItJdgU35a2ZNwHvdfHkZsCuF5WQDjbl30Jh7hzMZ80h37/KgZWDhfibMrDaZ+YxzicbcO2jMvUM6xqxrjkVEcpDCXUQkB2VruD8QdAEB0Jh7B425d+jxMWflPncRETm1bN1yFxGRU8i6cDezq8xsnZnVm9ldQdeTKmb2kJk1mtk7CW0Dzew5M1sffxwQbzcz+z/xn8EqMzs/uMq7z8yGm9kSM1tjZnVmdme8PWfHbWZFZvaGmb0VH/PX4u2jzez1+Jh/Hb8aHDMrjC/Xx9ePCrL+7jKzsJmtMLNn4ss5PV4AM9tsZm+b2Uozq423pe13O6vCPcm55bPVz4GrOrTdBSx29ypgcXwZYuOvin/dBvw4TTWmWhvwt+4+AZgBfCH+75nL424GLnf384ApwFVmNoPYPRC+Fx/zHmL3SIDcuVfCncCahOVcH+8xl7n7lITTHtP3u+3xW1xlwxdwEbAoYflu4O6g60rh+EYB7yQsrwOGxp8PBdbFn/8EuLmzftn8BfwWuKK3jBvoAywHLiR2QUtevP347zmxaT8uij/Pi/ezoGs/zXFWxoPscuAZYrPI5ux4E8a9GSjr0Ja23+2s2nInubnlc8lgd98OEH8sj7fn3M8h/uf3VOB1cnzc8V0UK4FG4DlgA7DXY/dCgA+PKxfulfB94O+AaHx5ELk93mMceNbMlpnZbfG2tP1uZ9sNspOaN74XyKmfg5mVAI8Df+Pu+09xE6+cGLe7twNTzKw/8CQwobNu8cesHrOZXQc0uvsyM5t1rLmTrjkx3g4udvdtZlYOPGdma0/RN+XjzrYt92Tmls8lO81sKED8sTHenjM/BzPLJxbsv3T3J+LNOT9uAHffCywldryhf/xeCPDhcSV1r4QMdjEw18w2E7tF5+XEtuRzdbzHufu2+GMjsQ/x6aTxdzvbwj2ZueVzSeI8+Z8jtk/6WPtfxo+wzwD2HftTL5tYbBP9p8Aad//XhFU5O24zi8S32DGzs4A5xA40LiF2LwT48zFn7b0S3P1ud69091HE/r++4O6fJUfHe4yZFZtZ6bHnwJXAO6Tzdzvogw7dOEhxDfAusf2U9wRdTwrH9TCwHWgl9il+K7F9jYuB9fHHgfG+RuysoQ3A20BN0PV3c8wzif3puQpYGf+6JpfHDUwGVsTH/A5wb7x9DPAGUA/8BiiMtxfFl+vj68cEPYYzGPss4JneMN74+N6Kf9Udy6p0/m7rClURkRyUbbtlREQkCQp3EZEcpHAXEclBCncRkRykcBcRyUEKdxGRHKRwFxHJQQp3EZEc9P8BubDNglhwoF8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
